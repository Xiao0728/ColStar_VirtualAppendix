{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "musical-diary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 12 14:42:07 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.74       Driver Version: 470.74       CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:1A:00.0 Off |                  N/A |\r\n",
      "| 41%   40C    P8    14W / 280W |      0MiB / 24220MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "secondary-obligation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "objective-gabriel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.1 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "latin-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "qrelsDev = pt.get_dataset(\"trec-deep-learning-passages\").get_qrels('dev')\n",
    "topicsDev = pt.get_dataset(\"trec-deep-learning-passages\").get_topics('dev')\n",
    "topicsDev = topicsDev.merge(qrelsDev[qrelsDev[\"label\"] > 0][[\"qid\"]].drop_duplicates()).head(1000)\n",
    "\n",
    "qrels2019 = pt.get_dataset(\"trec-deep-learning-passages\").get_qrels('test-2019')\n",
    "topics2019 = pt.get_dataset(\"trec-deep-learning-passages\").get_topics('test-2019')\n",
    "topics2019 = topics2019.merge(qrels2019[qrels2019[\"label\"] > 0][[\"qid\"]].drop_duplicates())\n",
    "\n",
    "qrels_2above2019 = qrels2019.copy()\n",
    "qrels_2above2019[\"label\"] = qrels_2above2019[\"label\"].apply(lambda value: value if value > 1 else 0)\n",
    "\n",
    "\n",
    "topics2020 = pt.get_dataset(\"trec-deep-learning-passages\").get_topics('test-2020')\n",
    "qrels2020 = pt.get_dataset(\"trec-deep-learning-passages\").get_qrels('test-2020')\n",
    "topics2020 = topics2020.merge(qrels2020[qrels2020[\"label\"] > 0][[\"qid\"]].drop_duplicates())\n",
    "\n",
    "qrels_2above2020 = qrels2020.copy()\n",
    "qrels_2above2020[\"label\"] = qrels_2above2020[\"label\"].apply(lambda value: value if value > 1 else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legendary-boards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing ColBERT: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ColBERT were not initialized from the model checkpoint at roberta-base and are newly initialized: ['linear.weight', 'roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 12, 14:43:16] #> Loading model checkpoint.\n",
      "[Feb 12, 14:43:16] #> Loading checkpoint /nfs/sean/workspace_xiao/ColRoberta/psg/train.py/ColRoberta_v1/checkpoints/colbert-90000.dnn\n",
      "[Feb 12, 14:43:20] #> checkpoint['epoch'] = 0\n",
      "[Feb 12, 14:43:20] #> checkpoint['batch'] = 90000\n",
      "-->Q_marker_token: [Q] -->tid 50265\n",
      "-->mask_token: <mask> -->tid 50264\n",
      "-->cls_token <s> -->tid 0\n",
      "-->sep_token </s> -->tid 2\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"/nfs/sean/workspace_xiao/ColRoberta/psg/train.py/ColRoberta_v1/checkpoints/colbert-90000.dnn\"\n",
    "\n",
    "from pyterrier_colbert.ranking import ColBERTFactory\n",
    "\n",
    "factory = ColBERTFactory(checkpoint_path, \"/nfs/sean/index_colroberta/\",\"msmarco_passage_index_colroberta90k_new\",faiss_partitions=100,memtype='mem'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "drawn-external",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 12, 14:43:30] #> Loading the FAISS index from /nfs/sean/index_colroberta/msmarco_passage_index_colroberta90k_new/ivfpq.100.faiss ..\n",
      "[Feb 12, 14:44:00] #> Building the emb2pid mapping..\n",
      "[Feb 12, 14:44:36] len(self.emb2pid) = 685796573\n",
      "Loading reranking index, memtype=mem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading index shards to memory: 100%|██████████| 127/127 [03:55<00:00,  1.85s/shard]\n"
     ]
    }
   ],
   "source": [
    "factory.faiss_index_on_gpu = False\n",
    "e2e = factory.end_to_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ideal-retreat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-->Q_marker_token: [Q] -->tid 50265\n",
      "-->mask_token: <mask> -->tid 50264\n",
      "-->cls_token <s> -->tid 0\n",
      "-->sep_token </s> -->tid 2\n",
      "[Feb 12, 14:48:38] #> Building the emb2tid mapping..\n",
      "685796573\n",
      ">>>vocab_size: 50267\n",
      "Loading doclens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyterrier_colbert.faiss_term_index.FaissNNTerm at 0x7f14b90e3290>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnt=factory.nn_term(df=True)\n",
    "fnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "copyrighted-acceptance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50265/50265 [00:00<00:00, 118098.02it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "num_docs=fnt.num_docs\n",
    "num_all_tokens = len(fnt.emb2tid) \n",
    "idfdict = {}\n",
    "probIDF = {}\n",
    "ictfdict = {}\n",
    "idflist=[]\n",
    "for tid in pt.tqdm(range(fnt.inference.query_tokenizer.tok.vocab_size)):\n",
    "    df = fnt.getDF_by_id(tid)\n",
    "    # for add one IDF score\n",
    "    idfscore = np.log((1+num_docs)/(df+1))\n",
    "    idfdict[tid] = idfscore\n",
    "    idflist.append(idfscore)\n",
    "    # for probalistic IDF score\n",
    "    probIDFscore = np.log((num_docs-df+0.5)/(df+0.5))\n",
    "    probIDF[tid] = probIDFscore\n",
    "    # for ICTF score\n",
    "    cf = fnt.getCTF_by_id(tid)\n",
    "    ictfscore = np.log((num_all_tokens+1)/(cf+1))\n",
    "    ictfdict[tid] = ictfscore\n",
    "    \n",
    "# for global normalisation idf scores    \n",
    "maxscore=max(idfdict.values())\n",
    "idfGN={}\n",
    "for key in idfdict:\n",
    "    idfGN[key] = idfdict[key]/maxscore\n",
    "# for global normalisation Probidf scores \n",
    "\n",
    "maxscoreProb=max(probIDF.values())\n",
    "probIDFGN={}\n",
    "for key in idfdict:\n",
    "    probIDFGN[key] = probIDF[key]/maxscoreProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cutting-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./resSIG/RQ1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "choice-columbus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment: 100%|██████████| 10/10 [25:15<00:00, 151.59s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>R(rel=2)@1000</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP(rel=2)@1000</th>\n",
       "      <th>RR(rel=2)@10</th>\n",
       "      <th>R(rel=2)@1000 +</th>\n",
       "      <th>R(rel=2)@1000 -</th>\n",
       "      <th>R(rel=2)@1000 p-value</th>\n",
       "      <th>nDCG@10 +</th>\n",
       "      <th>nDCG@10 -</th>\n",
       "      <th>nDCG@10 p-value</th>\n",
       "      <th>AP(rel=2)@1000 +</th>\n",
       "      <th>AP(rel=2)@1000 -</th>\n",
       "      <th>AP(rel=2)@1000 p-value</th>\n",
       "      <th>RR(rel=2)@10 +</th>\n",
       "      <th>RR(rel=2)@10 -</th>\n",
       "      <th>RR(rel=2)@10 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colroberta.rerank.index_score.dl19</td>\n",
       "      <td>0.755332</td>\n",
       "      <td>0.694702</td>\n",
       "      <td>0.458108</td>\n",
       "      <td>0.865116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>colroberta.e2e.dl19</td>\n",
       "      <td>0.733648</td>\n",
       "      <td>0.683896</td>\n",
       "      <td>0.426708</td>\n",
       "      <td>0.866279</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.630674</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.719107</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.456801</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.968939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name  R(rel=2)@1000   nDCG@10  \\\n",
       "0  colroberta.rerank.index_score.dl19       0.755332  0.694702   \n",
       "1                 colroberta.e2e.dl19       0.733648  0.683896   \n",
       "\n",
       "   AP(rel=2)@1000  RR(rel=2)@10  R(rel=2)@1000 +  R(rel=2)@1000 -  \\\n",
       "0        0.458108      0.865116              NaN              NaN   \n",
       "1        0.426708      0.866279             13.0             23.0   \n",
       "\n",
       "   R(rel=2)@1000 p-value  nDCG@10 +  nDCG@10 -  nDCG@10 p-value  \\\n",
       "0                    NaN        NaN        NaN              NaN   \n",
       "1               0.630674        4.0       12.0         0.719107   \n",
       "\n",
       "   AP(rel=2)@1000 +  AP(rel=2)@1000 -  AP(rel=2)@1000 p-value  RR(rel=2)@10 +  \\\n",
       "0               NaN               NaN                     NaN             NaN   \n",
       "1              12.0              28.0                0.456801             1.0   \n",
       "\n",
       "   RR(rel=2)@10 -  RR(rel=2)@10 p-value  \n",
       "0             NaN                   NaN  \n",
       "1             3.0              0.968939  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "df = pt.Experiment(\n",
    "    [\n",
    "     bm25_terrier_stemmed_text>> factory.index_scorer(),\n",
    "     e2e\n",
    "    ],\n",
    "    topics2019,\n",
    "    qrels2019,\n",
    "    batch_size=10, \n",
    "    verbose=True,\n",
    "    save_dir = \"./resSIG/RQ1/\",\n",
    "    filter_by_qrels=True,baseline=0,\n",
    "    eval_metrics=[nDCG@10,RR(rel=2)@10,  AP(rel=2)@1000, R(rel=2)@1000],\n",
    "    names=[\"colroberta.rerank.index_score.dl19\",\"colroberta.e2e.dl19\"]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "genuine-incidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment: 100%|██████████| 12/12 [32:21<00:00, 161.76s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>R(rel=2)@1000</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP(rel=2)@1000</th>\n",
       "      <th>RR(rel=2)@10</th>\n",
       "      <th>R(rel=2)@1000 +</th>\n",
       "      <th>R(rel=2)@1000 -</th>\n",
       "      <th>R(rel=2)@1000 p-value</th>\n",
       "      <th>nDCG@10 +</th>\n",
       "      <th>nDCG@10 -</th>\n",
       "      <th>nDCG@10 p-value</th>\n",
       "      <th>AP(rel=2)@1000 +</th>\n",
       "      <th>AP(rel=2)@1000 -</th>\n",
       "      <th>AP(rel=2)@1000 p-value</th>\n",
       "      <th>RR(rel=2)@10 +</th>\n",
       "      <th>RR(rel=2)@10 -</th>\n",
       "      <th>RR(rel=2)@10 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colroberta.rerank.index_score.dl20</td>\n",
       "      <td>0.807223</td>\n",
       "      <td>0.695075</td>\n",
       "      <td>0.462050</td>\n",
       "      <td>0.843541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>colroberta.e2e.dl20</td>\n",
       "      <td>0.763290</td>\n",
       "      <td>0.666198</td>\n",
       "      <td>0.423786</td>\n",
       "      <td>0.828395</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.241728</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>11.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.129054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name  R(rel=2)@1000   nDCG@10  \\\n",
       "0  colroberta.rerank.index_score.dl20       0.807223  0.695075   \n",
       "1                 colroberta.e2e.dl20       0.763290  0.666198   \n",
       "\n",
       "   AP(rel=2)@1000  RR(rel=2)@10  R(rel=2)@1000 +  R(rel=2)@1000 -  \\\n",
       "0        0.462050      0.843541              NaN              NaN   \n",
       "1        0.423786      0.828395             15.0             24.0   \n",
       "\n",
       "   R(rel=2)@1000 p-value  nDCG@10 +  nDCG@10 -  nDCG@10 p-value  \\\n",
       "0                    NaN        NaN        NaN              NaN   \n",
       "1               0.241728        8.0       22.0         0.017383   \n",
       "\n",
       "   AP(rel=2)@1000 +  AP(rel=2)@1000 -  AP(rel=2)@1000 p-value  RR(rel=2)@10 +  \\\n",
       "0               NaN               NaN                     NaN             NaN   \n",
       "1              11.0              40.0                0.018722             0.0   \n",
       "\n",
       "   RR(rel=2)@10 -  RR(rel=2)@10 p-value  \n",
       "0             NaN                   NaN  \n",
       "1             4.0              0.129054  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pyterrier.measures import *\n",
    "df = pt.Experiment(\n",
    "    [\n",
    "     bm25_terrier_stemmed_text>> factory.index_scorer(),\n",
    "     e2e\n",
    "    ],\n",
    "    topics2020,\n",
    "    qrels2020,\n",
    "    batch_size=10, \n",
    "    verbose=True,\n",
    "    save_dir = \"./resSIG/RQ1/\",\n",
    "    filter_by_qrels=True,baseline=0,\n",
    "    eval_metrics=[nDCG@10,RR(rel=2)@10,  AP(rel=2)@1000, R(rel=2)@1000],\n",
    "    names=[\"colroberta.rerank.index_score.dl20\",\"colroberta.e2e.dl20\"]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-workplace",
   "metadata": {},
   "source": [
    "# RQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "outer-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def _get_match_matrix(maxsim, idx,idsQ,idsD):\n",
    "    #dinx is the dinx th document token\n",
    "    #qinx is the qinx th query token\n",
    "    #for each q token, if the idsQ ==idsD--> exact match; other wise, idsQ=/=idsD-> semantic match\n",
    "    exact_match = torch.zeros_like(maxsim)\n",
    "    semantic_match = torch.zeros_like(maxsim)\n",
    "    for didx in range(len(idx)): #dinx the document \n",
    "        for qidx in range(len(idsQ[0])): # the qtoken\n",
    "    #         print(\"idsQ token:\",idsQ[0][qidx])\n",
    "            q_tid=idsQ[0][qidx]\n",
    "            max_dtok_index = idx[didx][qidx]\n",
    "            doc_maxsim_tid = idsD[didx][max_dtok_index]\n",
    "            if (q_tid == doc_maxsim_tid):\n",
    "#                 print(q_tid,\"exact matching now\")\n",
    "#                 print(\"yes\",\"didx=\", didx, q_tid)\n",
    "#                 print(factory.args.inference.query_tokenizer.tok.convert_ids_to_tokens([q_tid]))\n",
    "                exact_match[didx][qidx]=1\n",
    "            if (q_tid !=doc_maxsim_tid):\n",
    "#                 print(q_tid,\"semantic matching now\")\n",
    "                semantic_match[didx][qidx]=1\n",
    "    return exact_match, semantic_match\n",
    "\n",
    "\n",
    "\n",
    "from pyterrier.transformer import TransformerBase\n",
    "def scorer_test(factory, add_contributions=False, \n",
    "                add_exact_match_contribution=False,\n",
    "                add_question_exact_match_contribution=False, \n",
    "                verbose=False, gpu=True) -> TransformerBase:\n",
    "    \"\"\"\n",
    "    Calculates the ColBERT max_sim operator using previous encodings of queries and documents\n",
    "    input: qid, query_embs, [query_weights], docno, doc_embs\n",
    "    output: ditto + score, [+ contributions]\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import pyterrier as pt\n",
    "    assert pt.started(), 'PyTerrier must be started'\n",
    "    cuda0 = torch.device('cuda') if gpu else torch.device('cpu')\n",
    "\n",
    "    def _build_interaction(row, D):\n",
    "        doc_embs = row.doc_embs\n",
    "        doc_len = doc_embs.shape[0]\n",
    "        D[row.row_index, 0:doc_len, :] = doc_embs\n",
    "\n",
    "    def _build_toks(row, idsD):\n",
    "        doc_toks = row.doc_toks\n",
    "        doc_len = doc_toks.shape[0]\n",
    "        idsD[row.row_index, 0:doc_len] = doc_toks\n",
    "\n",
    "    def _score_query(df):\n",
    "        with torch.no_grad():\n",
    "            weightsQ = None\n",
    "            Q = torch.cat([df.iloc[0].query_embs])\n",
    "            if \"query_weights\" in df.columns:\n",
    "                weightsQ = df.iloc[0].query_weights\n",
    "            else:\n",
    "                weightsQ = torch.ones(Q.shape[0])\n",
    "            if gpu:\n",
    "                Q = Q.cuda()\n",
    "                weightsQ = weightsQ.cuda()        \n",
    "            D = torch.zeros(len(df), factory.args.doc_maxlen, factory.args.dim, device=cuda0)\n",
    "            df['row_index'] = range(len(df))\n",
    "            if verbose:\n",
    "                pt.tqdm.pandas(desc='scorer')\n",
    "                df.progress_apply(lambda row: _build_interaction(row, D), axis=1)\n",
    "            else:\n",
    "                df.apply(lambda row: _build_interaction(row, D), axis=1)\n",
    "            maxscoreQ = (Q @ D.permute(0, 2, 1)).max(2).values\n",
    "            scores = (weightsQ*maxscoreQ).sum(1).cpu()\n",
    "            df[\"score\"] = scores.tolist()\n",
    "#             if add_contributions:\n",
    "#                 contributions = (Q @ D.permute(0, 2, 1)).max(1).values.cpu()\n",
    "#                 df[\"contributions\"] = contributions.tolist()\n",
    "#             if add_exact_match_contribution:\n",
    "            idsQ = torch.cat([df.iloc[0].query_toks]).unsqueeze(0)\n",
    "            idsD = torch.zeros(len(df), factory.args.doc_maxlen, dtype=idsQ.dtype)\n",
    "\n",
    "            df.apply(lambda row: _build_toks(row, idsD), axis=1)\n",
    "            # which places in the query are actual tokens, not specials such as MASKs\n",
    "#             special_ids = [0,1,2,50264,50265,50266]\n",
    "#             ['<s>', '<pad>', '</s>', '<mask>', '[unused0]', '[unused1]']\n",
    "                \n",
    "            token_match = (idsQ != 50264) & (idsQ != 50265) & (idsQ !=50266) & (idsQ != 0) & (idsQ != 2)\n",
    "\n",
    "\n",
    "            ############get the denominator of all qtoekns excluding the special qtokens########\n",
    "            # perform the interaction\n",
    "            interaction = (Q @ D.permute(0, 2, 1)).cpu()\n",
    "            weightsQ = weightsQ.unsqueeze(0).cpu()\n",
    "            weighted_maxsim = weightsQ*interaction.max(2).values\n",
    "            # mask out query embeddings that arent tokens \n",
    "            weighted_maxsim[:, ~token_match[0,:]] = 0\n",
    "            # get the sum\n",
    "            denominator = weighted_maxsim.sum(1)\n",
    "\n",
    "\n",
    "            ############get the nemerator of exact and semantic excluding the special qtokens########\n",
    "\n",
    "            if add_exact_match_contribution:\n",
    "                # perform the interaction\n",
    "                interaction = (Q @ D.permute(0, 2, 1)).cpu()\n",
    "\n",
    "                maxsim, idx = interaction.max(2)\n",
    "                exact_match, semantic_match =_get_match_matrix(maxsim, idx, idsQ, idsD)\n",
    "                # mask out query embeddings that arent tokens \n",
    "                exact_match[:, ~token_match[0,:]] = 0\n",
    "                semantic_match[:, ~token_match[0,:]] = 0\n",
    "                weighted_maxsim = weightsQ*maxsim\n",
    "                weighted_maxsim_exact = weighted_maxsim*exact_match\n",
    "                weighted_maxsim_semantic = weighted_maxsim*semantic_match\n",
    "                # get the sum\n",
    "                numerator_exact = weighted_maxsim_exact.sum(1)\n",
    "                numerator_semantic = weighted_maxsim_semantic.sum(1)\n",
    "            elif add_question_exact_match_contribution:\n",
    "                \n",
    "                question_token_match = (idsQ!=61) & (idsQ!=141) &(idsQ!=99)&(idsQ!=147)&(idsQ!=596)&(idsQ!=54) &(idsQ!=77)\n",
    "                interaction = (Q @ D.permute(0, 2, 1)).cpu()\n",
    "                maxsim, idx = interaction.max(2)\n",
    "                exact_match, semantic_match =_get_match_matrix(maxsim, idx, idsQ, idsD)\n",
    "                # mask out query embeddings that arent tokens \n",
    "                exact_match[:, question_token_match[0,:]] = 0\n",
    "                semantic_match[:, question_token_match[0,:]] = 0\n",
    "                weighted_maxsim = weightsQ*maxsim\n",
    "                weighted_maxsim_exact = weighted_maxsim*exact_match\n",
    "                weighted_maxsim_semantic = weighted_maxsim*semantic_match\n",
    "                # get the sum\n",
    "                numerator_exact = weighted_maxsim_exact.sum(1)\n",
    "                numerator_semantic = weighted_maxsim_semantic.sum(1)\n",
    "#                 question_list=[61,   141,    99,   147,   596,    54,    77]\n",
    "        #         question_list = [5488,9178,12196,8569,25800,8155,14746]\n",
    "\n",
    "\n",
    "            #df[\"exact_count\"] = exact_match\n",
    "            df[\"exact_numer_exact\"] = numerator_exact.tolist()\n",
    "            df[\"semantic_numer_exact\"] = numerator_exact.tolist()\n",
    "            df[\"exact_denom\"] = denominator.tolist()\n",
    "            df[\"exact_pct\"] = (numerator_exact/denominator).tolist()\n",
    "            df[\"semantic_pct\"] = (numerator_semantic/denominator).tolist()\n",
    "            \n",
    "        return df\n",
    "\n",
    "    return pt.apply.by_query(_score_query, add_ranks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "injured-tracker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:48:56.485 [main] WARN org.terrier.structures.BaseCompressingMetaIndex - Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.9 GiB of memory would be required.\n"
     ]
    }
   ],
   "source": [
    "bm25_terrier_stemmed_text = pt.BatchRetrieve.from_dataset(\n",
    "    'msmarco_passage', \n",
    "    'terrier_stemmed_text', \n",
    "    wmodel='BM25',\n",
    "    metadata=['docno', 'text'], \n",
    "    num_results=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "hollow-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./resSIG/RQ4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "breeding-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./resSIG/RQ2/e2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "french-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./resSIG/RQ2/rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "elegant-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./resSIG/RQ3/e2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sweet-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./resSIG/RQ3/rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "located-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./resSIG/RQ4/e2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "finished-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./resSIG/RQ4/rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "immediate-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06532465167674405 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "       >>scorer_test(factory,add_exact_match_contribution=False,add_question_exact_match_contribution=True)\n",
    "      )\n",
    "\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/colroberta.rerank.Q.question.2019.res.txt\",index=False)\n",
    "allres_e2e.head()\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fatal-myrtle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06746009935725315 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "       >>scorer_test(factory,add_exact_match_contribution=False,add_question_exact_match_contribution=True)\n",
    "      )\n",
    "\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/colroberta.e2e.Q.question.2019.res.txt\",index=False)\n",
    "allres_e2e.head()\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-tractor",
   "metadata": {},
   "source": [
    "# RQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "little-diamond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which --> 5488\n",
      "how --> 9178\n",
      "what --> 12196\n",
      "where --> 8569\n",
      "why --> 25800\n",
      "who --> 8155\n",
      "when --> 14746\n"
     ]
    }
   ],
   "source": [
    "qtokens = [\"which\",\"how\",\"what\",\"where\",\"why\",\"who\",\"when\"]\n",
    "for token in qtokens:\n",
    "    print(token,\"-->\",fnt.inference.query_tokenizer.tok.convert_tokens_to_ids(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "japanese-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# if not os.path.exists(\"stopword-list.txt\"):\n",
    "#     !wget \"https://raw.githubusercontent.com/terrier-org/terrier-core/5.x/modules/core/src/main/resources/stopword-list.txt\"\n",
    "cuda0 = torch.device('cuda:0')\n",
    "stops=[]\n",
    "with open(\"stopword-list.txt\") as f:\n",
    "    for l in f:\n",
    "        stops.append(l.strip())\n",
    "Tokeniser = pt.autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()\n",
    "PorterStemmer = pt.autoclass(\"org.terrier.terms.PorterStemmer\")()\n",
    "def _get_doc_maxsim_tid_remarkable(doc_maxsim_tid,token,q_token, add_hash=False,add_stop=False,add_numeric=False,\n",
    "                      add_low=False,add_med=False,add_high=False,add_all=False,add_stem=False,add_question=False): \n",
    "#     didx,max_dtok_index,idsD,\n",
    "    if add_hash:\n",
    "        if token.startswith('Ġ'):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    elif add_stop:\n",
    "        token = token.replace('Ġ','')\n",
    "        if token in stops:\n",
    "            return True\n",
    "        else:\n",
    "            return False     \n",
    "    elif add_numeric:\n",
    "        token = token.replace('Ġ','')\n",
    "        if token.isnumeric():\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif add_stem:\n",
    "        q_token=q_token.replace('Ġ','')\n",
    "        token=token.replace('Ġ','')\n",
    "#         print(\".........\",q_token)\n",
    "        if PorterStemmer.stem(q_token) == PorterStemmer.stem(token):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "         \n",
    "    elif add_low:\n",
    "        if doc_maxsim_tid == 50266 or doc_maxsim_tid==50265:\n",
    "            return False\n",
    "        elif (idfdict[int(doc_maxsim_tid)]) < np.percentile(idflist,25):\n",
    "#             print(\"yes\",doc_maxsim_tid,idfdict[int(doc_maxsim_tid)] )\n",
    "#             print(\"25 perc:\",np.percentile(idflist,25))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif add_med:\n",
    "        if doc_maxsim_tid == 50266 or doc_maxsim_tid==50265:\n",
    "            return False\n",
    "        elif (np.percentile(idflist,25) <(idfdict[int(doc_maxsim_tid)])) &((idfdict[int(doc_maxsim_tid)])<np.percentile(idflist,75)):\n",
    "#             print(\"yes\",doc_maxsim_tid,idfdict[int(doc_maxsim_tid)] )\n",
    "            return True\n",
    "        else:\n",
    "#             print(\"No\",doc_maxsim_tid,idfdict[int(doc_maxsim_tid)] )\n",
    "            return False\n",
    "    elif add_high:\n",
    "        if doc_maxsim_tid == 50266 or doc_maxsim_tid==50265:\n",
    "            return False\n",
    "        elif (idfdict[int(doc_maxsim_tid)]) > np.percentile(idflist,75):\n",
    "#             print(\"yes\",doc_maxsim_tid,idfdict[int(doc_maxsim_tid)] )\n",
    "#             print(\"25 perc:\",np.percentile(idflist,75))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif add_question:\n",
    "        question_list=[61,   141,    99,   147,   596,    54,    77]\n",
    "#         question_list = [5488,9178,12196,8569,25800,8155,14746]\n",
    "        if int(doc_maxsim_tid) in question_list:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif add_all:\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "empirical-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_match_matrix_remarkable(maxsim, idx,idsQ,idsD, add_hash=False,add_stop=False,add_numeric=False,\n",
    "                      add_low=False,add_med=False,add_high=False,add_all=False,add_stem=False,add_question=False):\n",
    "    #dinx is the dinx th document token\n",
    "    #qinx is the qinx th query token\n",
    "    #for each q token, if the idsQ ==idsD--> exact match; other wise, idsQ=/=idsD-> semantic match\n",
    "    exact_match = torch.zeros_like(maxsim)\n",
    "    semantic_match = torch.zeros_like(maxsim)\n",
    "    for didx in range(len(idx)): #dinx the document \n",
    "#         print(\"idsD token\", didx)\n",
    "        for qidx in range(len(idsQ[0])): # the qtoken\n",
    "#             print(qidx,\"idsQ token:\",idsQ[0][qidx])\n",
    "            q_tid=idsQ[0][qidx]\n",
    "            max_dtok_index = idx[didx][qidx]\n",
    "#             print(\"qidx\", qidx, \"didx\",max_dtok_index)\n",
    "            doc_maxsim_tid = idsD[didx][max_dtok_index]\n",
    "            token =factory.args.inference.doc_tokenizer.tok.convert_ids_to_tokens([doc_maxsim_tid])[0]\n",
    "            q_token = factory.args.inference.query_tokenizer.tok.convert_ids_to_tokens([int(q_tid)])[0]\n",
    "#             print(doc_maxsim_tid)\n",
    "#             print(\"IDF score:\",idfdict[int(doc_maxsim_tid)])\n",
    "            # decide if the current doc token is a speical matching type\n",
    "            current_special_match = _get_doc_maxsim_tid_remarkable(doc_maxsim_tid,token,q_token,\n",
    "                                                                 add_hash=add_hash,add_stop=add_stop,add_numeric=add_numeric,\n",
    "                                                                 add_low=add_low,add_med=add_med,add_high=add_high,add_all=add_all,\n",
    "                                                                   add_stem=add_stem,add_question=add_question)\n",
    "            \n",
    "            if (q_tid == doc_maxsim_tid) & current_special_match:\n",
    "                d_token =factory.args.inference.doc_tokenizer.tok.convert_ids_to_tokens([doc_maxsim_tid])[0]                \n",
    "#                 print(\"special exact match---\",doc_maxsim_tid_special)\n",
    "#                 print(\"==exact match====>qid=\",qidx,\"dtoken\",d_token,\"qtoken\",q_token)\n",
    "                exact_match[didx][qidx]=1\n",
    "            if (q_tid != doc_maxsim_tid) & current_special_match:\n",
    "#                 print(\"qid=\",qidx, \"special semantic match---\",doc_maxsim_tid_special)\n",
    "#                 q_token = fnt.inference.query_tokenizer.tok.decode([q_tid])\n",
    "#                 print(\"==semantic match====>qid=\",qidx,\"dtoken\",token,\"qtoken\",q_token)\n",
    "                semantic_match[didx][qidx]=1\n",
    "#         break\n",
    "    return exact_match,semantic_match\n",
    "        \n",
    "#             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "involved-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyterrier.transformer import TransformerBase\n",
    "def scorer_test_remarkable(factory, add_contributions=False, \n",
    "                add_exact_match_contribution=False, verbose=False, gpu=True,\n",
    "                add_hash=False, add_stop=False, add_numeric=False,\n",
    "                add_low=False, add_med=False, add_high=False, add_all=False, add_stem=False,add_question=False) -> TransformerBase:\n",
    "    \"\"\"\n",
    "    Calculates the ColBERT max_sim operator using previous encodings of queries and documents\n",
    "    input: qid, query_embs, [query_weights], docno, doc_embs\n",
    "    output: ditto + score, [+ contributions]\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import pyterrier as pt\n",
    "    assert pt.started(), 'PyTerrier must be started'\n",
    "    cuda0 = torch.device('cuda') if gpu else torch.device('cpu')\n",
    "\n",
    "    def _build_interaction(row, D):\n",
    "        doc_embs = row.doc_embs\n",
    "        doc_len = doc_embs.shape[0]\n",
    "        D[row.row_index, 0:doc_len, :] = doc_embs\n",
    "\n",
    "    def _build_toks(row, idsD):\n",
    "        doc_toks = row.doc_toks\n",
    "        doc_len = doc_toks.shape[0]\n",
    "        idsD[row.row_index, 0:doc_len] = doc_toks\n",
    "\n",
    "    def _score_query(df):\n",
    "        with torch.no_grad():\n",
    "            weightsQ = None\n",
    "            Q = torch.cat([df.iloc[0].query_embs])\n",
    "            if \"query_weights\" in df.columns:\n",
    "                weightsQ = df.iloc[0].query_weights\n",
    "            else:\n",
    "                weightsQ = torch.ones(Q.shape[0])\n",
    "            if gpu:\n",
    "                Q = Q.cuda()\n",
    "                weightsQ = weightsQ.cuda()        \n",
    "            D = torch.zeros(len(df), factory.args.doc_maxlen, factory.args.dim, device=cuda0)\n",
    "            df['row_index'] = range(len(df))\n",
    "            if verbose:\n",
    "                pt.tqdm.pandas(desc='scorer')\n",
    "                df.progress_apply(lambda row: _build_interaction(row, D), axis=1)\n",
    "            else:\n",
    "                df.apply(lambda row: _build_interaction(row, D), axis=1)\n",
    "            maxscoreQ = (Q @ D.permute(0, 2, 1)).max(2).values\n",
    "            scores = (weightsQ*maxscoreQ).sum(1).cpu()\n",
    "            df[\"score\"] = scores.tolist()\n",
    "\n",
    "#             if add_exact_match_contribution:\n",
    "            idsQ = torch.cat([df.iloc[0].query_toks]).unsqueeze(0)\n",
    "            idsD = torch.zeros(len(df), factory.args.doc_maxlen, dtype=idsQ.dtype)\n",
    "\n",
    "            df.apply(lambda row: _build_toks(row, idsD), axis=1)\n",
    "\n",
    "            # which places in the query are actual tokens, not specials such as MASKs\n",
    "            token_match = (idsQ != 50264) & (idsQ != 50265) & (idsQ !=50266) & (idsQ != 0) & (idsQ != 2)\n",
    "#             token_match = (idsQ != 101) & (idsQ != 102) & (idsQ != 103) & (idsQ != 1) & (idsQ != 2)\n",
    "\n",
    "\n",
    "\n",
    "            ############get the denominator of all qtoekns excluding the special qtokens########\n",
    "            # perform the interaction\n",
    "            interaction = (Q @ D.permute(0, 2, 1)).cpu()\n",
    "            weightsQ = weightsQ.unsqueeze(0).cpu()\n",
    "            weighted_maxsim = weightsQ*interaction.max(2).values\n",
    "            # mask out query embeddings that arent tokens \n",
    "            weighted_maxsim[:, ~token_match[0,:]] = 0\n",
    "            # get the sum\n",
    "            denominator = weighted_maxsim.sum(1)\n",
    "            ##################################################################################\n",
    "\n",
    "\n",
    "            ############get the nemerator of exact and semantic excluding the special qtokens########\n",
    "            # perform the interaction\n",
    "            interaction = (Q @ D.permute(0, 2, 1)).cpu()\n",
    "\n",
    "            maxsim, idx = interaction.max(2)\n",
    "#             exact_match, semantic_match =_get_match_matrix(weighted_maxsim, idx, idsQ, idsD)\n",
    "            exact_match, semantic_match =_get_match_matrix_remarkable(maxsim, idx,idsQ,idsD, add_hash=add_hash,\n",
    "                                                                      add_stop=add_stop,add_numeric=add_numeric,\n",
    "                                                                      add_low=add_low,add_med=add_med,\n",
    "                                                                      add_high=add_high,add_all=add_all, \n",
    "                                                                      add_stem=add_stem,add_question=add_question)\n",
    "            # mask out query embeddings that arent tokens \n",
    "            exact_match[:, ~token_match[0,:]] = 0\n",
    "            semantic_match[:, ~token_match[0,:]] = 0\n",
    "            weighted_maxsim = weightsQ*maxsim\n",
    "            weighted_maxsim_exact = weighted_maxsim*exact_match\n",
    "            weighted_maxsim_semantic = weighted_maxsim*semantic_match\n",
    "            # get the sum\n",
    "            numerator_exact = weighted_maxsim_exact.sum(1)\n",
    "            numerator_semantic = weighted_maxsim_semantic.sum(1)\n",
    "            ##################################################################################\n",
    "\n",
    "            #df[\"exact_count\"] = exact_match\n",
    "            df[\"exact_numer_exact\"] = numerator_exact.tolist()\n",
    "            df[\"semantic_numer_exact\"] = numerator_semantic.tolist()\n",
    "            df[\"exact_denom\"] = denominator.tolist()\n",
    "            df[\"exact_pct\"] = (numerator_exact/denominator).tolist()\n",
    "            df[\"semantic_pct\"] = (numerator_semantic/denominator).tolist()\n",
    "\n",
    "        return df\n",
    "\n",
    "    return pt.apply.by_query(_score_query, add_ranks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "constant-category",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:48:26.898 [main] WARN org.terrier.structures.BaseCompressingMetaIndex - Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.9 GiB of memory would be required.\n"
     ]
    }
   ],
   "source": [
    "bm25_terrier_stemmed_text = pt.BatchRetrieve.from_dataset(\n",
    "    'msmarco_passage', \n",
    "    'terrier_stemmed_text', \n",
    "    wmodel='BM25',\n",
    "    metadata=['docno', 'text'], \n",
    "    num_results=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-center",
   "metadata": {},
   "source": [
    "## Doc-ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "spread-capture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.599345248625722 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_all=True))\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/rerank/colroberta.reranker.remarkable.doc_all.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "olive-handbook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6066283947389935 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_all=True))\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/rerank/colroberta.reranker.remarkable.doc_all.2020.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "corresponding-software",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6095695485996898 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_all=True))\n",
    "\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/e2e/colroberta.e2e.remarkable.doc_all.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "hidden-discussion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6216884158325918 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_all=True))\n",
    "\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/e2e/colroberta.e2e.remarkable.doc_all.2020.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-sigma",
   "metadata": {},
   "source": [
    "## RQ3: rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "sapphire-paradise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03889611282289406 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_stem=True))\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/rerank/colroberta.reranker.remarkable.doc_stem.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bored-aside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12757205864371254 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_hash=True))\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/rerank/colroberta.reranker.remarkable.doc_hash.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "combined-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_exact_match_contribution=False, verbose=False, gpu=True,\n",
    "#                 add_hash=False, add_stop=True, add_numeric=False,\n",
    "#                 add_low=False, add_med=False, add_high=False, add_all=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "searching-milton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005744403940930679 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_numeric=True))\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/rerank/colroberta.reranker.remarkable.doc_numeric.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "liberal-animation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14139532245475067 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_stop=True))\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/rerank/colroberta.reranker.remarkable.doc_stop.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "assumed-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.487303629864094 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_low=True))\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/rerank/colroberta.reranker.remarkable.doc_low.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "familiar-turtle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07869722935160421 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_med=True))\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/rerank/colroberta.reranker.remarkable.doc_med.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "reported-findings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009619723525032181 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_high=True))\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/rerank/colroberta.reranker.remarkable.doc_high.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-breeding",
   "metadata": {},
   "source": [
    "## RQ3: e2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "measured-break",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1328545758622771 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_hash=True))\n",
    "\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/e2e/colroberta.e2e.remarkable.doc_hash.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "diverse-chicago",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03997996219494882 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_stem=True))\n",
    "\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/e2e/colroberta.e2e.remarkable.doc_stem.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "manual-chinese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15475443139057962 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_stop=True))\n",
    "\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/e2e/colroberta.e2e.remarkable.doc_stop.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "given-emerald",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003893541057946566 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_numeric=True))\n",
    "\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/e2e/colroberta.e2e.remarkable.doc_numeric.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "advanced-crazy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5015838839602016 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_low=True))\n",
    "\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/e2e/colroberta.e2e.remarkable.doc_low.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "documented-modification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0768625603449269 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_med=True))\n",
    "\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/e2e/colroberta.e2e.remarkable.doc_med.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "swedish-seattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007171841562739386 at rankcutoff 10\n"
     ]
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_test_remarkable(factory,add_high=True))\n",
    "\n",
    "allres_e2e =pd.concat(pipe.transform_gen(topics2019,batch_size=1))\n",
    "allres_e2e = allres_e2e.drop(columns=['query_toks', 'query_embs'])\n",
    "allres_e2e.to_csv(\"./resSIG/RQ3/e2e/colroberta.e2e.remarkable.doc_high.2019.res.txt\",index=False)\n",
    "# allres_e2e\n",
    "\n",
    "import numpy as np\n",
    "total_rankoff=np.arange(0,51)\n",
    "mean_smp=[]\n",
    "for i in total_rankoff:\n",
    "    \n",
    "    smp= allres_e2e[allres_e2e['rank'] <= i].groupby(['qid', 'query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    if i==10:\n",
    "        print(smp,\"at rankcutoff 10\")\n",
    "    mean_smp.append(smp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-texas",
   "metadata": {},
   "source": [
    "# RQ4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "robust-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_match_matrix_RQ4(maxsim, idx,idsQ,idsD):\n",
    "    #dinx is the dinx th document token\n",
    "    #qinx is the qinx th query token\n",
    "    #for each q token, if the idsQ ==idsD--> exact match; other wise, idsQ=/=idsD-> semantic match\n",
    "    exact_match = torch.zeros_like(maxsim)\n",
    "    semantic_match = torch.zeros_like(maxsim)\n",
    "    for didx in range(len(idx)): #dinx the document \n",
    "        for qidx in range(len(idsQ[0])): # the qtoken\n",
    "    #         print(\"idsQ token:\",idsQ[0][qidx])\n",
    "            q_tid=idsQ[0][qidx]\n",
    "            max_dtok_index = idx[didx][qidx]\n",
    "            doc_maxsim_tid = idsD[didx][max_dtok_index]\n",
    "            if (q_tid == doc_maxsim_tid):\n",
    "                exact_match[didx][qidx]=1\n",
    "            if (q_tid != doc_maxsim_tid):\n",
    "                semantic_match[didx][qidx]=1\n",
    "    return exact_match, semantic_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "wrong-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier.transformer import TransformerBase\n",
    "def exact_scorer_RQ4(factory, add_contributions=False, add_exact_match_contribution=False, all_types_scoring=False,\n",
    "                 only_exact_scoring=False, only_semantic_scoring=False, only_special_scoring=False,only_qtokens_scoring=False,\n",
    "                 verbose=False, gpu=True) -> TransformerBase:\n",
    "    \"\"\"\n",
    "    Calculates the ColBERT max_sim operator using previous encodings of queries and documents\n",
    "    input: qid, query_embs, [query_weights], docno, doc_embs\n",
    "    output: ditto + score, [+ contributions]\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import pyterrier as pt\n",
    "    assert pt.started(), 'PyTerrier must be started'\n",
    "    cuda0 = torch.device('cuda') if gpu else torch.device('cpu')\n",
    "\n",
    "    def _build_interaction(row, D):\n",
    "        doc_embs = row.doc_embs\n",
    "        doc_len = doc_embs.shape[0]\n",
    "        D[row.row_index, 0:doc_len, :] = doc_embs\n",
    "\n",
    "    def _build_toks(row, idsD):\n",
    "        doc_toks = row.doc_toks\n",
    "        doc_len = doc_toks.shape[0]\n",
    "        idsD[row.row_index, 0:doc_len] = doc_toks\n",
    "\n",
    "    def _score_query(df):\n",
    "        with torch.no_grad():\n",
    "            weightsQ = None\n",
    "            Q = torch.cat([df.iloc[0].query_embs])\n",
    "            if \"query_weights\" in df.columns:\n",
    "                weightsQ = df.iloc[0].query_weights\n",
    "            else:\n",
    "                weightsQ = torch.ones(Q.shape[0])\n",
    "            if gpu:\n",
    "                Q = Q.cuda()\n",
    "                weightsQ = weightsQ.cuda()        \n",
    "            D = torch.zeros(len(df), factory.args.doc_maxlen, factory.args.dim, device=cuda0)\n",
    "            df['row_index'] = range(len(df))\n",
    "            if verbose:\n",
    "                pt.tqdm.pandas(desc='scorer')\n",
    "                df.progress_apply(lambda row: _build_interaction(row, D), axis=1)\n",
    "            else:\n",
    "                df.apply(lambda row: _build_interaction(row, D), axis=1)\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "            idsQ = torch.cat([df.iloc[0].query_toks]).unsqueeze(0)\n",
    "            idsD = torch.zeros(len(df), factory.args.doc_maxlen, dtype=idsQ.dtype)\n",
    "\n",
    "            df.apply(lambda row: _build_toks(row, idsD), axis=1)\n",
    "#             print(idsQ.shape,\"!!!!!!!!!!!\")\n",
    "\n",
    "            \n",
    "#                 print(\">>> Performing only exact scoring\")\n",
    "            # which places in the query are actual tokens, not specials such as MASKs\n",
    "#             token_match = (idsQ != 101) & (idsQ != 102) & (idsQ != 103) & (idsQ != 1) & (idsQ != 2)\n",
    "            token_match = (idsQ != 50264) & (idsQ != 50265) & (idsQ !=50266) & (idsQ != 0) & (idsQ != 2)\n",
    "\n",
    "\n",
    "\n",
    "            ############get the nemerator of exact and semantic excluding the special qtokens########\n",
    "            # perform the interaction\n",
    "            interaction = (Q @ D.permute(0, 2, 1)).cpu()\n",
    "            maxsim, idx = interaction.max(2)\n",
    "            \n",
    "            exact_match, semantic_match =_get_match_matrix_RQ4(maxsim, idx, idsQ, idsD)\n",
    "            exact_match[:, ~token_match[0,:]] = 0\n",
    "            semantic_match[:, ~token_match[0,:]] = 0\n",
    "\n",
    "            weightsQ = weightsQ.unsqueeze(0).cpu()\n",
    "            weighted_maxsim = weightsQ*maxsim\n",
    "\n",
    "            weighted_maxsim_exact = weighted_maxsim*exact_match\n",
    "            weighted_maxsim_semantic = weighted_maxsim*semantic_match\n",
    "\n",
    "            if only_exact_scoring:\n",
    "                df[\"score\"] = weighted_maxsim_exact.sum(1).cpu().tolist()\n",
    "    \n",
    "            elif only_semantic_scoring:\n",
    "                df[\"score\"] = weighted_maxsim_semantic.sum(1).cpu().tolist()\n",
    "            elif only_special_scoring:\n",
    "#                 print(\">>> Performing only special scoring\")\n",
    "                # which places in the query are actual tokens, not specials, \n",
    "                # including [Q]:1,[D]:2,[SEP]:102,[CLS]:101, NOT <mask>:50264\n",
    "                special_token_match =  (idsQ == 50265) | (idsQ == 0) | (idsQ == 2)\n",
    "#                 token_match = (idsQ != 50264) & (idsQ != 50265) & (idsQ !=50266) & (idsQ != 1) & (idsQ != 2)\n",
    "                 # perform the interaction\n",
    "                interaction = (Q @ D.permute(0, 2, 1)).cpu()\n",
    "#                 weightsQ = weightsQ.unsqueeze(0).cpu()\n",
    "                weighted_maxsim = weightsQ*interaction.max(2).values\n",
    "                # mask out query embeddings that arent tokens \n",
    "                weighted_maxsim[:, ~special_token_match[0,:]] = 0\n",
    "                df[\"score\"] = weighted_maxsim.sum(1).cpu().tolist()\n",
    "            elif only_qtokens_scoring:\n",
    "#                 print(\">>> Performing only query actual tokens scoring\")\n",
    "                # which places in the query are actual tokens, not specials such as MASKs\n",
    "#                 token_match = (idsQ != 101) & (idsQ != 102) & (idsQ != 103) & (idsQ != 1) & (idsQ != 2)\n",
    "                token_match = (idsQ != 50264) & (idsQ != 50265) & (idsQ !=50266) & (idsQ != 1) & (idsQ != 2)\n",
    "                special_token_match = (idsQ == 101) | (idsQ == 102) | (idsQ == 103) | (idsQ == 1) | (idsQ == 2)\n",
    "                 # perform the interaction\n",
    "                interaction = (Q @ D.permute(0, 2, 1)).cpu()\n",
    "#                 weightsQ = weightsQ.unsqueeze(0).cpu()\n",
    "                weighted_maxsim = weightsQ*interaction.max(2).values\n",
    "                # mask out query embeddings that arent special tokens -->only the actual tokens\n",
    "                weighted_maxsim[:, special_token_match[0,:]] = 0\n",
    "                df[\"score\"] = weighted_maxsim.sum(1).cpu().tolist()\n",
    "                \n",
    "            elif all_types_scoring:\n",
    "#                 print(\">>> Performing all types of scoring\")\n",
    "                maxscoreQ = (Q @ D.permute(0, 2, 1)).max(2).values\n",
    "                maxscoreQ = maxscoreQ.cpu()\n",
    "                scores = (weightsQ*maxscoreQ).sum(1)#.cpu()\n",
    "                df[\"score\"] = scores.tolist()\n",
    "        return df\n",
    "\n",
    "    return pt.apply.by_query(_score_query, add_ranks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "former-convert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '</s>', '[unused0]']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tid = [0,2,50265]\n",
    "token = fnt.inference.query_tokenizer.tok.convert_ids_to_tokens(tid)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "solar-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_pipe_only_exact = (\n",
    "    factory.set_retrieve()\n",
    "    >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)\n",
    "    >> factory.fetch_index_encodings(ids=True)\n",
    "    >> exact_scorer_RQ4(factory,only_exact_scoring=True,only_semantic_scoring=False,only_special_scoring=False,all_types_scoring=False)\n",
    ")\n",
    "\n",
    "e2e_pipe_only_semantic = (\n",
    "    factory.set_retrieve()\n",
    "    >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)\n",
    "    >> factory.fetch_index_encodings(ids=True)\n",
    "    >> exact_scorer_RQ4(factory,only_exact_scoring=False,only_semantic_scoring=True,only_special_scoring=False,all_types_scoring=False)\n",
    ")\n",
    "\n",
    "\n",
    "e2e_pipe_only_qspecial = (\n",
    "    factory.set_retrieve() \n",
    "    >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)\n",
    "    >> factory.fetch_index_encodings(ids=True)\n",
    "    >> exact_scorer_RQ4(factory,only_exact_scoring=False,only_semantic_scoring=False,only_special_scoring=True,all_types_scoring=False)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "e2e_pipe_all_types = (\n",
    "    factory.set_retrieve()\n",
    "    >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)\n",
    "    >> factory.fetch_index_encodings(ids=True)\n",
    "    >> exact_scorer_RQ4(factory,only_exact_scoring=False,only_semantic_scoring=False,only_special_scoring=False,all_types_scoring=True)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "illegal-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "reranker_all_types = (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")\n",
    "                      >>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >> exact_scorer_RQ4(factory,only_exact_scoring=False,only_semantic_scoring=False,only_special_scoring=False,all_types_scoring=True)\n",
    ")\n",
    "\n",
    "reranker_only_exact = (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >> exact_scorer_RQ4(factory,only_exact_scoring=True,only_semantic_scoring=False,only_special_scoring=False,all_types_scoring=False)\n",
    ")\n",
    "\n",
    "reranker_only_semantic = (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >> exact_scorer_RQ4(factory,only_exact_scoring=False,only_semantic_scoring=True,only_special_scoring=False,all_types_scoring=False)\n",
    ")\n",
    "\n",
    "reranker_only_qspecial = (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >> exact_scorer_RQ4(factory,only_exact_scoring=False,only_semantic_scoring=False,only_special_scoring=True,all_types_scoring=False)\n",
    ")\n",
    "\n",
    "# reranker_only_qtokens = (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "#        >>factory.fetch_index_encodings(ids=True)\n",
    "#         >> exact_scorer_RQ4(factory,only_qtokens_scoring=True, only_exact_scoring=False,only_semantic_scoring=False,only_special_scoring=False,all_types_scoring=False)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "enormous-ballot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_ce819_row0_col4,#T_ce819_row1_col4,#T_ce819_row2_col4,#T_ce819_row3_col4,#T_ce819_row4_col1,#T_ce819_row4_col2,#T_ce819_row4_col3,#T_ce819_row4_col4,#T_ce819_row4_col5,#T_ce819_row4_col6,#T_ce819_row8_col7{\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_ce819_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >name</th>        <th class=\"col_heading level0 col1\" >nDCG@10</th>        <th class=\"col_heading level0 col2\" >nDCG@100</th>        <th class=\"col_heading level0 col3\" >R(rel=2)@100</th>        <th class=\"col_heading level0 col4\" >R(rel=2)@1000</th>        <th class=\"col_heading level0 col5\" >AP(rel=2)@100</th>        <th class=\"col_heading level0 col6\" >AP(rel=2)@1000</th>        <th class=\"col_heading level0 col7\" >RR(rel=2)@10</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ce819_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_ce819_row0_col0\" class=\"data row0 col0\" >bm25</td>\n",
       "                        <td id=\"T_ce819_row0_col1\" class=\"data row0 col1\" >0.479540</td>\n",
       "                        <td id=\"T_ce819_row0_col2\" class=\"data row0 col2\" >0.487416</td>\n",
       "                        <td id=\"T_ce819_row0_col3\" class=\"data row0 col3\" >0.488133</td>\n",
       "                        <td id=\"T_ce819_row0_col4\" class=\"data row0 col4\" >0.755332</td>\n",
       "                        <td id=\"T_ce819_row0_col5\" class=\"data row0 col5\" >0.232165</td>\n",
       "                        <td id=\"T_ce819_row0_col6\" class=\"data row0 col6\" >0.286448</td>\n",
       "                        <td id=\"T_ce819_row0_col7\" class=\"data row0 col7\" >0.639655</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce819_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_ce819_row1_col0\" class=\"data row1 col0\" >colroberta.reranker.only_exact</td>\n",
       "                        <td id=\"T_ce819_row1_col1\" class=\"data row1 col1\" >0.384937</td>\n",
       "                        <td id=\"T_ce819_row1_col2\" class=\"data row1 col2\" >0.381257</td>\n",
       "                        <td id=\"T_ce819_row1_col3\" class=\"data row1 col3\" >0.389464</td>\n",
       "                        <td id=\"T_ce819_row1_col4\" class=\"data row1 col4\" >0.755332</td>\n",
       "                        <td id=\"T_ce819_row1_col5\" class=\"data row1 col5\" >0.200675</td>\n",
       "                        <td id=\"T_ce819_row1_col6\" class=\"data row1 col6\" >0.247086</td>\n",
       "                        <td id=\"T_ce819_row1_col7\" class=\"data row1 col7\" >0.513178</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce819_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_ce819_row2_col0\" class=\"data row2 col0\" >colroberta.reranker.only_semantic</td>\n",
       "                        <td id=\"T_ce819_row2_col1\" class=\"data row2 col1\" >0.336138</td>\n",
       "                        <td id=\"T_ce819_row2_col2\" class=\"data row2 col2\" >0.297520</td>\n",
       "                        <td id=\"T_ce819_row2_col3\" class=\"data row2 col3\" >0.283583</td>\n",
       "                        <td id=\"T_ce819_row2_col4\" class=\"data row2 col4\" >0.755332</td>\n",
       "                        <td id=\"T_ce819_row2_col5\" class=\"data row2 col5\" >0.133509</td>\n",
       "                        <td id=\"T_ce819_row2_col6\" class=\"data row2 col6\" >0.169996</td>\n",
       "                        <td id=\"T_ce819_row2_col7\" class=\"data row2 col7\" >0.534976</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce819_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_ce819_row3_col0\" class=\"data row3 col0\" >colroberta.reranker.only_special</td>\n",
       "                        <td id=\"T_ce819_row3_col1\" class=\"data row3 col1\" >0.616003</td>\n",
       "                        <td id=\"T_ce819_row3_col2\" class=\"data row3 col2\" >0.526134</td>\n",
       "                        <td id=\"T_ce819_row3_col3\" class=\"data row3 col3\" >0.507032</td>\n",
       "                        <td id=\"T_ce819_row3_col4\" class=\"data row3 col4\" >0.755332</td>\n",
       "                        <td id=\"T_ce819_row3_col5\" class=\"data row3 col5\" >0.315465</td>\n",
       "                        <td id=\"T_ce819_row3_col6\" class=\"data row3 col6\" >0.360428</td>\n",
       "                        <td id=\"T_ce819_row3_col7\" class=\"data row3 col7\" >0.821152</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce819_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_ce819_row4_col0\" class=\"data row4 col0\" >colroberta.reranker.all_types</td>\n",
       "                        <td id=\"T_ce819_row4_col1\" class=\"data row4 col1\" >0.694702</td>\n",
       "                        <td id=\"T_ce819_row4_col2\" class=\"data row4 col2\" >0.625814</td>\n",
       "                        <td id=\"T_ce819_row4_col3\" class=\"data row4 col3\" >0.588650</td>\n",
       "                        <td id=\"T_ce819_row4_col4\" class=\"data row4 col4\" >0.755332</td>\n",
       "                        <td id=\"T_ce819_row4_col5\" class=\"data row4 col5\" >0.410903</td>\n",
       "                        <td id=\"T_ce819_row4_col6\" class=\"data row4 col6\" >0.458108</td>\n",
       "                        <td id=\"T_ce819_row4_col7\" class=\"data row4 col7\" >0.865116</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce819_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_ce819_row5_col0\" class=\"data row5 col0\" >colroberta.only_exact</td>\n",
       "                        <td id=\"T_ce819_row5_col1\" class=\"data row5 col1\" >0.344064</td>\n",
       "                        <td id=\"T_ce819_row5_col2\" class=\"data row5 col2\" >0.303896</td>\n",
       "                        <td id=\"T_ce819_row5_col3\" class=\"data row5 col3\" >0.297057</td>\n",
       "                        <td id=\"T_ce819_row5_col4\" class=\"data row5 col4\" >0.550312</td>\n",
       "                        <td id=\"T_ce819_row5_col5\" class=\"data row5 col5\" >0.151375</td>\n",
       "                        <td id=\"T_ce819_row5_col6\" class=\"data row5 col6\" >0.177360</td>\n",
       "                        <td id=\"T_ce819_row5_col7\" class=\"data row5 col7\" >0.482171</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce819_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_ce819_row6_col0\" class=\"data row6 col0\" >colroberta.only_semantic</td>\n",
       "                        <td id=\"T_ce819_row6_col1\" class=\"data row6 col1\" >0.244679</td>\n",
       "                        <td id=\"T_ce819_row6_col2\" class=\"data row6 col2\" >0.186454</td>\n",
       "                        <td id=\"T_ce819_row6_col3\" class=\"data row6 col3\" >0.179471</td>\n",
       "                        <td id=\"T_ce819_row6_col4\" class=\"data row6 col4\" >0.316685</td>\n",
       "                        <td id=\"T_ce819_row6_col5\" class=\"data row6 col5\" >0.092963</td>\n",
       "                        <td id=\"T_ce819_row6_col6\" class=\"data row6 col6\" >0.103355</td>\n",
       "                        <td id=\"T_ce819_row6_col7\" class=\"data row6 col7\" >0.375000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce819_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_ce819_row7_col0\" class=\"data row7 col0\" >colroberta.only_speical</td>\n",
       "                        <td id=\"T_ce819_row7_col1\" class=\"data row7 col1\" >0.551086</td>\n",
       "                        <td id=\"T_ce819_row7_col2\" class=\"data row7 col2\" >0.417015</td>\n",
       "                        <td id=\"T_ce819_row7_col3\" class=\"data row7 col3\" >0.399721</td>\n",
       "                        <td id=\"T_ce819_row7_col4\" class=\"data row7 col4\" >0.626167</td>\n",
       "                        <td id=\"T_ce819_row7_col5\" class=\"data row7 col5\" >0.247329</td>\n",
       "                        <td id=\"T_ce819_row7_col6\" class=\"data row7 col6\" >0.273701</td>\n",
       "                        <td id=\"T_ce819_row7_col7\" class=\"data row7 col7\" >0.801772</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ce819_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_ce819_row8_col0\" class=\"data row8 col0\" >colroberta.all_types</td>\n",
       "                        <td id=\"T_ce819_row8_col1\" class=\"data row8 col1\" >0.683896</td>\n",
       "                        <td id=\"T_ce819_row8_col2\" class=\"data row8 col2\" >0.581919</td>\n",
       "                        <td id=\"T_ce819_row8_col3\" class=\"data row8 col3\" >0.559191</td>\n",
       "                        <td id=\"T_ce819_row8_col4\" class=\"data row8 col4\" >0.733648</td>\n",
       "                        <td id=\"T_ce819_row8_col5\" class=\"data row8 col5\" >0.389557</td>\n",
       "                        <td id=\"T_ce819_row8_col6\" class=\"data row8 col6\" >0.426708</td>\n",
       "                        <td id=\"T_ce819_row8_col7\" class=\"data row8 col7\" >0.866279</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f0faa943ed0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "res1 = pt.Experiment(\n",
    "    [\n",
    "    bm25_terrier_stemmed_text,\n",
    "    reranker_only_exact,\n",
    "    reranker_only_semantic,\n",
    "    reranker_only_qspecial,\n",
    "#     reranker_only_qtokens,\n",
    "    reranker_all_types,\n",
    "    e2e_pipe_only_exact,\n",
    "    e2e_pipe_only_semantic,\n",
    "    e2e_pipe_only_qspecial,\n",
    "#     e2e_pipe_only_qtokens,\n",
    "    e2e_pipe_all_types\n",
    "    ],\n",
    "    topics2019,\n",
    "    qrels2019,\n",
    "    save_dir=\"./resSIG/RQ4/\",\n",
    "    filter_by_qrels=True,\n",
    "    batch_size=10,highlight=\"bold\",\n",
    "    eval_metrics = [nDCG@10,nDCG@100, R(rel=2)@100,R(rel=2)@1000, AP(rel=2)@100,AP(rel=2)@1000,RR(rel=2)@10], # Note: using R@1000 here instead of R(rel=2)@1000 to match the measure used by the TCT-ColBERT paper\n",
    "    names=[\n",
    "        'bm25',\n",
    "           \"colroberta.reranker.only_exact\",\"colroberta.reranker.only_semantic\",\n",
    "           \"colroberta.reranker.only_special\",\"colroberta.reranker.all_types\",\n",
    "        \"colroberta.only_exact\",\"colroberta.only_semantic\",\n",
    "        \"colroberta.only_speical\",\"colroberta.all_types\"]\n",
    ")\n",
    "\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "universal-teach",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment: 100%|██████████| 10/10 [01:36<00:00,  9.61s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>RR(rel=2)@10</th>\n",
       "      <th>AP(rel=2)@1000</th>\n",
       "      <th>R(rel=2)@1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bm25.colroberta_index_scorer</td>\n",
       "      <td>0.694702</td>\n",
       "      <td>0.865116</td>\n",
       "      <td>0.458108</td>\n",
       "      <td>0.755332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bm25.colroberta_text_scorer</td>\n",
       "      <td>0.694920</td>\n",
       "      <td>0.865891</td>\n",
       "      <td>0.458888</td>\n",
       "      <td>0.755332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name   nDCG@10  RR(rel=2)@10  AP(rel=2)@1000  \\\n",
       "0  bm25.colroberta_index_scorer  0.694702      0.865116        0.458108   \n",
       "1   bm25.colroberta_text_scorer  0.694920      0.865891        0.458888   \n",
       "\n",
       "   R(rel=2)@1000  \n",
       "0       0.755332  \n",
       "1       0.755332  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "df = pt.Experiment(\n",
    "    [bm25_terrier_stemmed_text>>factory.index_scorer() ,\n",
    "     bm25_terrier_stemmed_text>>factory.text_scorer() \n",
    "    ],\n",
    "    topics2019,\n",
    "    qrels2019,\n",
    "    batch_size=10, \n",
    "    verbose=True,\n",
    "    filter_by_qrels=True,\n",
    "    eval_metrics=[nDCG@10,RR(rel=2)@10,  AP(rel=2)@1000, R(rel=2)@1000],\n",
    "    names=[\"bm25.colroberta_index_scorer\",\"bm25.colroberta_text_scorer\"]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "optical-september",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment: 100%|██████████| 5/5 [00:10<00:00,  2.20s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>RR(rel=2)@10</th>\n",
       "      <th>AP(rel=2)@1000</th>\n",
       "      <th>R(rel=2)@1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pipe</td>\n",
       "      <td>0.694702</td>\n",
       "      <td>0.865116</td>\n",
       "      <td>0.458108</td>\n",
       "      <td>0.755332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name   nDCG@10  RR(rel=2)@10  AP(rel=2)@1000  R(rel=2)@1000\n",
       "0  pipe  0.694702      0.865116        0.458108       0.755332"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe =(factory.query_encoder() \n",
    "       >>bm25_terrier_stemmed_text\n",
    "       >>factory.fetch_index_encodings(ids=True) \n",
    "       >> factory.scorer()\n",
    "      )\n",
    "\n",
    "from pyterrier.measures import *\n",
    "df = pt.Experiment(\n",
    "    [pipe\n",
    "    ],\n",
    "    topics2019,\n",
    "    qrels2019,\n",
    "    batch_size=10, \n",
    "    verbose=True,\n",
    "    filter_by_qrels=True,\n",
    "    eval_metrics=[nDCG@10,RR(rel=2)@10,  AP(rel=2)@1000, R(rel=2)@1000],\n",
    "    names=[\"pipe\"]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "removable-worse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment: 100%|██████████| 5/5 [01:28<00:00, 17.77s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>RR(rel=2)@10</th>\n",
       "      <th>AP(rel=2)@1000</th>\n",
       "      <th>R(rel=2)@1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pipe2</td>\n",
       "      <td>0.694702</td>\n",
       "      <td>0.865116</td>\n",
       "      <td>0.458108</td>\n",
       "      <td>0.755332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name   nDCG@10  RR(rel=2)@10  AP(rel=2)@1000  R(rel=2)@1000\n",
       "0  pipe2  0.694702      0.865116        0.458108       0.755332"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2 =(factory.query_encoder() \n",
    "       >>bm25_terrier_stemmed_text>>factory.text_encoder()\n",
    "       >>factory.fetch_index_encodings(ids=True) \n",
    "       >> factory.scorer()\n",
    "      )\n",
    "\n",
    "from pyterrier.measures import *\n",
    "df = pt.Experiment(\n",
    "    [pipe2\n",
    "    ],\n",
    "    topics2019,\n",
    "    qrels2019,\n",
    "    batch_size=10, \n",
    "    verbose=True,\n",
    "    filter_by_qrels=True,\n",
    "    eval_metrics=[nDCG@10,RR(rel=2)@10,  AP(rel=2)@1000, R(rel=2)@1000],\n",
    "    names=[\"pipe2\"]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "invisible-routine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment: 100%|██████████| 5/5 [01:25<00:00, 17.02s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>RR(rel=2)@10</th>\n",
       "      <th>AP(rel=2)@1000</th>\n",
       "      <th>R(rel=2)@1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pipe2</td>\n",
       "      <td>0.69492</td>\n",
       "      <td>0.865891</td>\n",
       "      <td>0.458874</td>\n",
       "      <td>0.755332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  nDCG@10  RR(rel=2)@10  AP(rel=2)@1000  R(rel=2)@1000\n",
       "0  pipe2  0.69492      0.865891        0.458874       0.755332"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2 =(factory.query_encoder() \n",
    "       >>bm25_terrier_stemmed_text>>factory.text_encoder()\n",
    "#        >>factory.fetch_index_encodings(ids=True) \n",
    "       >> factory.scorer()\n",
    "      )\n",
    "\n",
    "from pyterrier.measures import *\n",
    "df = pt.Experiment(\n",
    "    [pipe2\n",
    "    ],\n",
    "    topics2019,\n",
    "    qrels2019,\n",
    "    batch_size=10, \n",
    "    verbose=True,\n",
    "    filter_by_qrels=True,\n",
    "    eval_metrics=[nDCG@10,RR(rel=2)@10,  AP(rel=2)@1000, R(rel=2)@1000],\n",
    "    names=[\"pipe2\"]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "patent-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe =(factory.query_encoder() \n",
    "       >>bm25_terrier_stemmed_text>>factory.text_encoder()\n",
    "#        >>factory.fetch_index_encodings(ids=True) \n",
    "#        >> factory.scorer()\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "brown-respect",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3188: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "      <th>query_embs</th>\n",
       "      <th>query_toks</th>\n",
       "      <th>doc_embs</th>\n",
       "      <th>doc_toks</th>\n",
       "      <th>row_index</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156493</td>\n",
       "      <td>8182161</td>\n",
       "      <td>8182161</td>\n",
       "      <td>A: While goldfish can grow up to 18 inches in ...</td>\n",
       "      <td>26.247568</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0665), tensor(-0.0652), tensor(0.01...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(83), tensor(...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156493</td>\n",
       "      <td>6139386</td>\n",
       "      <td>6139386</td>\n",
       "      <td>A: The conditions goldfish are kept in plus th...</td>\n",
       "      <td>27.030985</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0683), tensor(-0.0823), tensor(0.02...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(83), tensor(...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156493</td>\n",
       "      <td>3288600</td>\n",
       "      <td>3288600</td>\n",
       "      <td>A goldfish will grow to the depth of the water...</td>\n",
       "      <td>27.795626</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0409), tensor(-0.0439), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(83), tensor(...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156493</td>\n",
       "      <td>3288596</td>\n",
       "      <td>3288596</td>\n",
       "      <td>If the tank is not large enough to allow the g...</td>\n",
       "      <td>26.118546</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0308), tensor(-0.0117), tensor(0.01...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(318), tensor...</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156493</td>\n",
       "      <td>2259183</td>\n",
       "      <td>2259183</td>\n",
       "      <td>A large tank gives your goldfish plenty of roo...</td>\n",
       "      <td>26.127874</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0387), tensor(-0.0711), tensor(0.04...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(83), tensor(...</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>156493</td>\n",
       "      <td>2698003</td>\n",
       "      <td>2698003</td>\n",
       "      <td>My Favorite (Itchy Skin) Dog. I am allergic to...</td>\n",
       "      <td>13.535547</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0847), tensor(-0.0644), tensor(-0.1...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(1308), tenso...</td>\n",
       "      <td>995</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>156493</td>\n",
       "      <td>3125672</td>\n",
       "      <td>3125672</td>\n",
       "      <td>There's nothing in the agency's fishing laws a...</td>\n",
       "      <td>14.549792</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(-0.0869), tensor(-0.0093), tensor(-0....</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(345), tensor...</td>\n",
       "      <td>996</td>\n",
       "      <td>993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>156493</td>\n",
       "      <td>3258878</td>\n",
       "      <td>3258878</td>\n",
       "      <td>Some claim Goldie is the largest goldfish in B...</td>\n",
       "      <td>21.747154</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0190), tensor(-0.0522), tensor(-0.0...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(993), tensor...</td>\n",
       "      <td>997</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>156493</td>\n",
       "      <td>3261015</td>\n",
       "      <td>3261015</td>\n",
       "      <td>1Badly made or done. we're not paying good mon...</td>\n",
       "      <td>14.760541</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0771), tensor(0.0713), tensor(0.010...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(112), tensor...</td>\n",
       "      <td>998</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>156493</td>\n",
       "      <td>3603925</td>\n",
       "      <td>3603925</td>\n",
       "      <td>HOW OLD IS MY GOLDFISH? Discussion in 'Fish &amp; ...</td>\n",
       "      <td>15.127362</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0854), tensor(-0.2209), tensor(0.04...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(22062), tens...</td>\n",
       "      <td>999</td>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        qid    docid    docno  \\\n",
       "0    156493  8182161  8182161   \n",
       "1    156493  6139386  6139386   \n",
       "2    156493  3288600  3288600   \n",
       "3    156493  3288596  3288596   \n",
       "4    156493  2259183  2259183   \n",
       "..      ...      ...      ...   \n",
       "995  156493  2698003  2698003   \n",
       "996  156493  3125672  3125672   \n",
       "997  156493  3258878  3258878   \n",
       "998  156493  3261015  3261015   \n",
       "999  156493  3603925  3603925   \n",
       "\n",
       "                                                  text      score  \\\n",
       "0    A: While goldfish can grow up to 18 inches in ...  26.247568   \n",
       "1    A: The conditions goldfish are kept in plus th...  27.030985   \n",
       "2    A goldfish will grow to the depth of the water...  27.795626   \n",
       "3    If the tank is not large enough to allow the g...  26.118546   \n",
       "4    A large tank gives your goldfish plenty of roo...  26.127874   \n",
       "..                                                 ...        ...   \n",
       "995  My Favorite (Itchy Skin) Dog. I am allergic to...  13.535547   \n",
       "996  There's nothing in the agency's fishing laws a...  14.549792   \n",
       "997  Some claim Goldie is the largest goldfish in B...  21.747154   \n",
       "998  1Badly made or done. we're not paying good mon...  14.760541   \n",
       "999  HOW OLD IS MY GOLDFISH? Discussion in 'Fish & ...  15.127362   \n",
       "\n",
       "                query                                         query_embs  \\\n",
       "0    do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "1    do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "2    do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "3    do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "4    do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "..                ...                                                ...   \n",
       "995  do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "996  do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "997  do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "998  do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "999  do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "\n",
       "                                            query_toks  \\\n",
       "0    [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "1    [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "2    [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "3    [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "4    [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "..                                                 ...   \n",
       "995  [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "996  [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "997  [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "998  [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "999  [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "\n",
       "                                              doc_embs  \\\n",
       "0    [[tensor(0.0665), tensor(-0.0652), tensor(0.01...   \n",
       "1    [[tensor(0.0683), tensor(-0.0823), tensor(0.02...   \n",
       "2    [[tensor(0.0409), tensor(-0.0439), tensor(0.03...   \n",
       "3    [[tensor(0.0308), tensor(-0.0117), tensor(0.01...   \n",
       "4    [[tensor(0.0387), tensor(-0.0711), tensor(0.04...   \n",
       "..                                                 ...   \n",
       "995  [[tensor(0.0847), tensor(-0.0644), tensor(-0.1...   \n",
       "996  [[tensor(-0.0869), tensor(-0.0093), tensor(-0....   \n",
       "997  [[tensor(0.0190), tensor(-0.0522), tensor(-0.0...   \n",
       "998  [[tensor(0.0771), tensor(0.0713), tensor(0.010...   \n",
       "999  [[tensor(0.0854), tensor(-0.2209), tensor(0.04...   \n",
       "\n",
       "                                              doc_toks  row_index  rank  \n",
       "0    [tensor(0), tensor(50266), tensor(83), tensor(...          0    22  \n",
       "1    [tensor(0), tensor(50266), tensor(83), tensor(...          1    11  \n",
       "2    [tensor(0), tensor(50266), tensor(83), tensor(...          2     2  \n",
       "3    [tensor(0), tensor(50266), tensor(318), tensor...          3    28  \n",
       "4    [tensor(0), tensor(50266), tensor(83), tensor(...          4    26  \n",
       "..                                                 ...        ...   ...  \n",
       "995  [tensor(0), tensor(50266), tensor(1308), tenso...        995   997  \n",
       "996  [tensor(0), tensor(50266), tensor(345), tensor...        996   993  \n",
       "997  [tensor(0), tensor(50266), tensor(993), tensor...        997   311  \n",
       "998  [tensor(0), tensor(50266), tensor(112), tensor...        998   989  \n",
       "999  [tensor(0), tensor(50266), tensor(22062), tens...        999   983  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipe(topics2019.head(1))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "organic-apache",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:3188: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "      <th>query_embs</th>\n",
       "      <th>query_toks</th>\n",
       "      <th>doc_embs</th>\n",
       "      <th>doc_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156493</td>\n",
       "      <td>8182161</td>\n",
       "      <td>8182161</td>\n",
       "      <td>A: While goldfish can grow up to 18 inches in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>31.156444</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0665), tensor(-0.0652), tensor(0.01...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(83), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156493</td>\n",
       "      <td>6139386</td>\n",
       "      <td>6139386</td>\n",
       "      <td>A: The conditions goldfish are kept in plus th...</td>\n",
       "      <td>1</td>\n",
       "      <td>31.032333</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0683), tensor(-0.0823), tensor(0.02...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(83), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156493</td>\n",
       "      <td>3288600</td>\n",
       "      <td>3288600</td>\n",
       "      <td>A goldfish will grow to the depth of the water...</td>\n",
       "      <td>2</td>\n",
       "      <td>30.953843</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0409), tensor(-0.0439), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(83), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156493</td>\n",
       "      <td>3288596</td>\n",
       "      <td>3288596</td>\n",
       "      <td>If the tank is not large enough to allow the g...</td>\n",
       "      <td>3</td>\n",
       "      <td>30.754021</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0308), tensor(-0.0117), tensor(0.01...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(318), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156493</td>\n",
       "      <td>2259183</td>\n",
       "      <td>2259183</td>\n",
       "      <td>A large tank gives your goldfish plenty of roo...</td>\n",
       "      <td>4</td>\n",
       "      <td>30.362477</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0387), tensor(-0.0711), tensor(0.04...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(83), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>156493</td>\n",
       "      <td>2698003</td>\n",
       "      <td>2698003</td>\n",
       "      <td>My Favorite (Itchy Skin) Dog. I am allergic to...</td>\n",
       "      <td>995</td>\n",
       "      <td>13.581453</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0847), tensor(-0.0644), tensor(-0.1...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(1308), tenso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>156493</td>\n",
       "      <td>3125672</td>\n",
       "      <td>3125672</td>\n",
       "      <td>There's nothing in the agency's fishing laws a...</td>\n",
       "      <td>996</td>\n",
       "      <td>13.581453</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(-0.0869), tensor(-0.0093), tensor(-0....</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(345), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>156493</td>\n",
       "      <td>3258878</td>\n",
       "      <td>3258878</td>\n",
       "      <td>Some claim Goldie is the largest goldfish in B...</td>\n",
       "      <td>997</td>\n",
       "      <td>13.581453</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0190), tensor(-0.0522), tensor(-0.0...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(993), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>156493</td>\n",
       "      <td>3261015</td>\n",
       "      <td>3261015</td>\n",
       "      <td>1Badly made or done. we're not paying good mon...</td>\n",
       "      <td>998</td>\n",
       "      <td>13.581453</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0771), tensor(0.0713), tensor(0.010...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(112), tensor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>156493</td>\n",
       "      <td>3603925</td>\n",
       "      <td>3603925</td>\n",
       "      <td>HOW OLD IS MY GOLDFISH? Discussion in 'Fish &amp; ...</td>\n",
       "      <td>999</td>\n",
       "      <td>13.581453</td>\n",
       "      <td>do goldfish grow</td>\n",
       "      <td>[[tensor(0.0736), tensor(-0.0878), tensor(0.03...</td>\n",
       "      <td>[tensor(0), tensor(50265), tensor(109), tensor...</td>\n",
       "      <td>[[tensor(0.0854), tensor(-0.2209), tensor(0.04...</td>\n",
       "      <td>[tensor(0), tensor(50266), tensor(22062), tens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        qid    docid    docno  \\\n",
       "0    156493  8182161  8182161   \n",
       "1    156493  6139386  6139386   \n",
       "2    156493  3288600  3288600   \n",
       "3    156493  3288596  3288596   \n",
       "4    156493  2259183  2259183   \n",
       "..      ...      ...      ...   \n",
       "995  156493  2698003  2698003   \n",
       "996  156493  3125672  3125672   \n",
       "997  156493  3258878  3258878   \n",
       "998  156493  3261015  3261015   \n",
       "999  156493  3603925  3603925   \n",
       "\n",
       "                                                  text  rank      score  \\\n",
       "0    A: While goldfish can grow up to 18 inches in ...     0  31.156444   \n",
       "1    A: The conditions goldfish are kept in plus th...     1  31.032333   \n",
       "2    A goldfish will grow to the depth of the water...     2  30.953843   \n",
       "3    If the tank is not large enough to allow the g...     3  30.754021   \n",
       "4    A large tank gives your goldfish plenty of roo...     4  30.362477   \n",
       "..                                                 ...   ...        ...   \n",
       "995  My Favorite (Itchy Skin) Dog. I am allergic to...   995  13.581453   \n",
       "996  There's nothing in the agency's fishing laws a...   996  13.581453   \n",
       "997  Some claim Goldie is the largest goldfish in B...   997  13.581453   \n",
       "998  1Badly made or done. we're not paying good mon...   998  13.581453   \n",
       "999  HOW OLD IS MY GOLDFISH? Discussion in 'Fish & ...   999  13.581453   \n",
       "\n",
       "                query                                         query_embs  \\\n",
       "0    do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "1    do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "2    do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "3    do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "4    do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "..                ...                                                ...   \n",
       "995  do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "996  do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "997  do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "998  do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "999  do goldfish grow  [[tensor(0.0736), tensor(-0.0878), tensor(0.03...   \n",
       "\n",
       "                                            query_toks  \\\n",
       "0    [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "1    [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "2    [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "3    [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "4    [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "..                                                 ...   \n",
       "995  [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "996  [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "997  [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "998  [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "999  [tensor(0), tensor(50265), tensor(109), tensor...   \n",
       "\n",
       "                                              doc_embs  \\\n",
       "0    [[tensor(0.0665), tensor(-0.0652), tensor(0.01...   \n",
       "1    [[tensor(0.0683), tensor(-0.0823), tensor(0.02...   \n",
       "2    [[tensor(0.0409), tensor(-0.0439), tensor(0.03...   \n",
       "3    [[tensor(0.0308), tensor(-0.0117), tensor(0.01...   \n",
       "4    [[tensor(0.0387), tensor(-0.0711), tensor(0.04...   \n",
       "..                                                 ...   \n",
       "995  [[tensor(0.0847), tensor(-0.0644), tensor(-0.1...   \n",
       "996  [[tensor(-0.0869), tensor(-0.0093), tensor(-0....   \n",
       "997  [[tensor(0.0190), tensor(-0.0522), tensor(-0.0...   \n",
       "998  [[tensor(0.0771), tensor(0.0713), tensor(0.010...   \n",
       "999  [[tensor(0.0854), tensor(-0.2209), tensor(0.04...   \n",
       "\n",
       "                                              doc_toks  \n",
       "0    [tensor(0), tensor(50266), tensor(83), tensor(...  \n",
       "1    [tensor(0), tensor(50266), tensor(83), tensor(...  \n",
       "2    [tensor(0), tensor(50266), tensor(83), tensor(...  \n",
       "3    [tensor(0), tensor(50266), tensor(318), tensor...  \n",
       "4    [tensor(0), tensor(50266), tensor(83), tensor(...  \n",
       "..                                                 ...  \n",
       "995  [tensor(0), tensor(50266), tensor(1308), tenso...  \n",
       "996  [tensor(0), tensor(50266), tensor(345), tensor...  \n",
       "997  [tensor(0), tensor(50266), tensor(993), tensor...  \n",
       "998  [tensor(0), tensor(50266), tensor(112), tensor...  \n",
       "999  [tensor(0), tensor(50266), tensor(22062), tens...  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2 =(factory.query_encoder() \n",
    "       >>bm25_terrier_stemmed_text>>factory.text_encoder()\n",
    "       >>factory.fetch_index_encodings(ids=True) \n",
    "#        >> factory.scorer()\n",
    "      )\n",
    "df1=pipe2(topics2019.head(1))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-reviewer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
