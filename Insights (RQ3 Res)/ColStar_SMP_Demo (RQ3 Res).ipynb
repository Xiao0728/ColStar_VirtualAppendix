{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consecutive-valuation",
   "metadata": {},
   "source": [
    "# This notebook demonstrate the experiments for the RQ3 in our paper, namely:\n",
    "\n",
    "- RQ3.1 How does the semantic matching behaviour vary across different contextualised late interaction models? \n",
    "\n",
    "- RQ3.2 Can we characterise the salient token families of matches, i.e., which type of tokens contribute the most to semantic matching? \n",
    "\n",
    "- RQ3.3: Can we quantify the contribution of different types of \\xiao{matching behaviour, namely the lexical match and semantic match as well as special token match,} to the retrieval effectiveness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "other-guinea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.1 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "pt.init(tqdm='notebook')\n",
    "from pyterrier.measures import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "reported-pride",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6980"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "qrelsDev = pt.get_dataset(\"trec-deep-learning-passages\").get_qrels('dev.small')\n",
    "topicsDev = pt.get_dataset(\"trec-deep-learning-passages\").get_topics('dev.small')\n",
    "topicsDev = topicsDev.merge(qrelsDev[qrelsDev[\"label\"] > 0][[\"qid\"]].drop_duplicates())\n",
    "len(topicsDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "industrial-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qrels2019 = pt.get_dataset(\"trec-deep-learning-passages\").get_qrels('test-2019')\n",
    "topics2019 = pt.get_dataset(\"trec-deep-learning-passages\").get_topics('test-2019')\n",
    "\n",
    "topics2020 = pt.get_dataset(\"trec-deep-learning-passages\").get_topics('test-2020')\n",
    "qrels2020 = pt.get_dataset(\"trec-deep-learning-passages\").get_qrels('test-2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "anonymous-defense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colbert-190000.dnn  colbert-200000.dnn\tcolbert.dnn\r\n"
     ]
    }
   ],
   "source": [
    "!ls /nfstrecdl/workspace_xiao/ColBERT/psg/train.py/ColBERT_base_uncased_cosine_resume/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dirty-setting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 20, 13:45:25] #> Loading model checkpoint.\n",
      "[Feb 20, 13:45:25] #> Loading checkpoint /nfs/sean/workspace_xiao/ColBERT/psg/train.py/ColBERT_base_uncased_cosine_resume/checkpoints/colbert-200000.dnn\n",
      "[Feb 20, 13:45:28] #> checkpoint['epoch'] = 0\n",
      "[Feb 20, 13:45:28] #> checkpoint['batch'] = 200000\n"
     ]
    }
   ],
   "source": [
    "from pyterrier_colbert.ranking import ColBERTFactory\n",
    "checkpoint_loc = \"/nfs/sean/workspace_xiao/ColBERT/psg/train.py/ColBERT_base_uncased_cosine_resume/checkpoints/colbert-200000.dnn\"\n",
    "\n",
    "factory = ColBERTFactory(\n",
    "    checkpoint_loc,\n",
    "    \"/nfs/sean/workspace_xiao/\",\"colbert_cosine_index\",faiss_partitions=100,memtype='mem'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hourly-purpose",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 20, 13:45:38] #> Loading the FAISS index from /nfs/sean/workspace_xiao/colbert_cosine_index/ivfpq.100.faiss ..\n",
      "[Feb 20, 13:46:06] #> Building the emb2pid mapping..\n",
      "[Feb 20, 13:46:44] len(self.emb2pid) = 687758954\n",
      "Loading reranking index, memtype=mem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading index shards to memory: 100%|██████████| 19/19 [03:20<00:00, 10.57s/shard]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feb 20, 13:50:11] #> Building the emb2tid mapping..\n",
      "687758954\n",
      ">>>vocab_size: 30522\n",
      "Loading doclens\n"
     ]
    }
   ],
   "source": [
    "factory.faiss_index_on_gpu = False\n",
    "e2e_cosine = factory.end_to_end()\n",
    "fnt=factory.nn_term(df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "younger-composition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:10:50.693 [main] WARN org.terrier.structures.BaseCompressingMetaIndex - Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.9 GiB of memory would be required.\n"
     ]
    }
   ],
   "source": [
    "bm25_terrier_stemmed_text = pt.BatchRetrieve.from_dataset(\n",
    "    'msmarco_passage', \n",
    "    'terrier_stemmed_text', \n",
    "    wmodel='BM25',\n",
    "    metadata=['docno', 'text'], \n",
    "    num_results=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-venture",
   "metadata": {},
   "source": [
    "# Measure the SMP for RQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dress-walter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30522/30522 [00:00<00:00, 263887.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "num_docs=fnt.num_docs\n",
    "num_all_tokens = len(fnt.emb2tid) \n",
    "idfdict = {}\n",
    "probIDF = {}\n",
    "ictfdict = {}\n",
    "idflist=[]\n",
    "for tid in pt.tqdm(range(fnt.inference.query_tokenizer.tok.vocab_size)):\n",
    "    df = fnt.getDF_by_id(tid)\n",
    "    idfscore = np.log((1+num_docs)/(df+1))\n",
    "    idfdict[tid] = idfscore\n",
    "    idflist.append(idfscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "female-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"stopword-list.txt\"):\n",
    "    !wget \"https://raw.githubusercontent.com/terrier-org/terrier-core/5.x/modules/core/src/main/resources/stopword-list.txt\"\n",
    "cuda0 = torch.device('cuda:0')\n",
    "stops=[]\n",
    "with open(\"stopword-list.txt\") as f:\n",
    "    for l in f:\n",
    "        stops.append(l.strip())\n",
    "Tokeniser = pt.autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()\n",
    "PorterStemmer = pt.autoclass(\"org.terrier.terms.PorterStemmer\")()\n",
    "\n",
    "def _get_doc_maxsim_tid_remarkable(doc_maxsim_tid,token,q_token, add_subword=False,add_stop=False,add_numeric=False,\n",
    "                      add_low=False,add_med=False,add_high=False,add_all=False, add_stem=False,add_question=False): \n",
    "    if add_subword:\n",
    "        if token.startswith(\"##\"):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif add_stop:\n",
    "        token = token.replace(\"##\",\"\")\n",
    "        if token in stops:\n",
    "            return True\n",
    "        else:\n",
    "            return False     \n",
    "    elif add_numeric:\n",
    "        token = token.replace(\"##\",\"\")\n",
    "        if token.isnumeric():\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    elif add_low:\n",
    "      \n",
    "        if (idfdict[int(doc_maxsim_tid)]) < np.percentile(idflist,25):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif add_stem:\n",
    "        q_token=q_token.replace('##','')\n",
    "        token=token.replace('##','')\n",
    "        if PorterStemmer.stem(q_token) == PorterStemmer.stem(token):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif add_med:\n",
    "        if (np.percentile(idflist,25) <(idfdict[int(doc_maxsim_tid)])) &((idfdict[int(doc_maxsim_tid)])<np.percentile(idflist,75)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif add_high:\n",
    "        if (idfdict[int(doc_maxsim_tid)]) > np.percentile(idflist,75):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif add_all:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "premier-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_match_matrix_remarkable(maxsim, idx,idsQ,idsD, add_subword=False,add_stop=False,add_numeric=False,\n",
    "                      add_low=False,add_med=False,add_high=False,add_all=False,add_stem=False,add_question=False):\n",
    "    exact_match = torch.zeros_like(maxsim)\n",
    "    semantic_match = torch.zeros_like(maxsim)\n",
    "    for didx in range(len(idx)): \n",
    "        for qidx in range(len(idsQ[0])): \n",
    "            q_tid=idsQ[0][qidx]\n",
    "            max_dtok_index = idx[didx][qidx]\n",
    "            doc_maxsim_tid = idsD[didx][max_dtok_index]\n",
    "            token =factory.args.inference.doc_tokenizer.tok.convert_ids_to_tokens([doc_maxsim_tid])[0]\n",
    "            q_token = factory.args.inference.query_tokenizer.tok.convert_ids_to_tokens([int(q_tid)])[0]\n",
    "          \n",
    "            current_special_match = _get_doc_maxsim_tid_remarkable(doc_maxsim_tid,token,q_token,\n",
    "                                                                 add_subword=add_subword,add_stop=add_stop,\n",
    "                                                                 add_numeric=add_numeric,\n",
    "                                                                 add_low=add_low,add_med=add_med,add_high=add_high,add_all=add_all,\n",
    "                                                                 add_stem=add_stem)\n",
    "            \n",
    "            if (q_tid == doc_maxsim_tid) & current_special_match:\n",
    "                d_token =factory.args.inference.doc_tokenizer.tok.convert_ids_to_tokens([doc_maxsim_tid])[0]                \n",
    "                exact_match[didx][qidx]=1\n",
    "            if (q_tid != doc_maxsim_tid) & current_special_match:\n",
    "                semantic_match[didx][qidx]=1\n",
    "    return exact_match,semantic_match           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "civic-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyterrier.transformer import TransformerBase\n",
    "def scorer_smp(factory,  verbose=False, gpu=True,\n",
    "                add_subword=False, add_stop=False, add_numeric=False,\n",
    "                add_low=False, add_med=False, add_high=False, \n",
    "                add_all=False, add_stem=False,add_question=False) -> TransformerBase:\n",
    "    \"\"\"\n",
    "    Calculates the ColBERT max_sim operator using previous encodings of queries and documents\n",
    "    input: qid, query_embs, [query_weights], docno, doc_embs\n",
    "    output: ditto + score, [+ contributions]\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import pyterrier as pt\n",
    "    assert pt.started(), 'PyTerrier must be started'\n",
    "    cuda0 = torch.device('cuda') if gpu else torch.device('cpu')\n",
    "\n",
    "    def _build_interaction(row, D):\n",
    "        doc_embs = row.doc_embs\n",
    "        doc_len = doc_embs.shape[0]\n",
    "        D[row.row_index, 0:doc_len, :] = doc_embs\n",
    "\n",
    "    def _build_toks(row, idsD):\n",
    "        doc_toks = row.doc_toks\n",
    "        doc_len = doc_toks.shape[0]\n",
    "        idsD[row.row_index, 0:doc_len] = doc_toks\n",
    "\n",
    "    def _score_query(df):\n",
    "        with torch.no_grad():\n",
    "            weightsQ = None\n",
    "            Q = torch.cat([df.iloc[0].query_embs])\n",
    "            if \"query_weights\" in df.columns:\n",
    "                weightsQ = df.iloc[0].query_weights\n",
    "            else:\n",
    "                weightsQ = torch.ones(Q.shape[0])\n",
    "            if gpu:\n",
    "                Q = Q.cuda()\n",
    "                weightsQ = weightsQ.cuda()        \n",
    "            D = torch.zeros(len(df), factory.args.doc_maxlen, factory.args.dim, device=cuda0)\n",
    "            df['row_index'] = range(len(df))\n",
    "            if verbose:\n",
    "                pt.tqdm.pandas(desc='scorer')\n",
    "                df.progress_apply(lambda row: _build_interaction(row, D), axis=1)\n",
    "            else:\n",
    "                df.apply(lambda row: _build_interaction(row, D), axis=1)\n",
    "            maxscoreQ = (Q @ D.permute(0, 2, 1)).max(2).values\n",
    "            scores = (weightsQ*maxscoreQ).sum(1).cpu()\n",
    "            df[\"score\"] = scores.tolist()\n",
    "\n",
    "#             if add_exact_match_contribution:\n",
    "            idsQ = torch.cat([df.iloc[0].query_toks]).unsqueeze(0)\n",
    "            idsD = torch.zeros(len(df), factory.args.doc_maxlen, dtype=idsQ.dtype)\n",
    "\n",
    "            df.apply(lambda row: _build_toks(row, idsD), axis=1)\n",
    "\n",
    "            # which places in the query are actual tokens, not specials such as MASKs\n",
    "            token_match = (idsQ != 101) & (idsQ != 102) & (idsQ != 103) & (idsQ != 1) & (idsQ != 2)\n",
    "            question_match =  (idsQ != 2029)& (idsQ != 2129)& (idsQ != 2054)& (idsQ != 2073) & (idsQ != 2339)& (idsQ != 2040) & (idsQ != 2043)\n",
    "\n",
    "            # perform the interaction\n",
    "            interaction = (Q @ D.permute(0, 2, 1)).cpu()\n",
    "            weightsQ = weightsQ.unsqueeze(0).cpu()\n",
    "            weighted_maxsim = weightsQ*interaction.max(2).values\n",
    "            # mask out query embeddings that arent tokens \n",
    "            weighted_maxsim[:, ~token_match[0,:]] = 0\n",
    "            # get the sum\n",
    "            denominator = weighted_maxsim.sum(1)\n",
    "           \n",
    "            if add_question:\n",
    "                interaction = (Q @ D.permute(0, 2, 1)).cpu()\n",
    "\n",
    "                maxsim, idx = interaction.max(2)\n",
    "                exact_match, semantic_match =_get_match_matrix(weighted_maxsim, idx, idsQ, idsD)\n",
    "                # mask out query embeddings that arent tokens \n",
    "                exact_match[:, question_match[0,:]] = 0\n",
    "                semantic_match[:, question_match[0,:]] = 0\n",
    "                weighted_maxsim = weightsQ*maxsim\n",
    "                weighted_maxsim_exact = weighted_maxsim*exact_match\n",
    "                weighted_maxsim_semantic = weighted_maxsim*semantic_match\n",
    "                # get the sum\n",
    "                numerator_exact = weighted_maxsim_exact.sum(1)\n",
    "                numerator_semantic = weighted_maxsim_semantic.sum(1)\n",
    "            else:\n",
    "                interaction = (Q @ D.permute(0, 2, 1)).cpu()\n",
    "\n",
    "                maxsim, idx = interaction.max(2)\n",
    "   \n",
    "                exact_match, semantic_match =_get_match_matrix_remarkable(maxsim, idx,idsQ,idsD, add_subword=add_subword,\n",
    "                                                                          add_stop=add_stop,add_numeric=add_numeric,\n",
    "                                                                          add_low=add_low,add_med=add_med,\n",
    "                                                                          add_high=add_high,add_all=add_all, \n",
    "                                                                          add_stem=add_stem,add_question=add_question)\n",
    "                # mask out query embeddings that arent tokens \n",
    "                exact_match[:, ~token_match[0,:]] = 0\n",
    "                semantic_match[:, ~token_match[0,:]] = 0\n",
    "                weighted_maxsim = weightsQ*maxsim\n",
    "                weighted_maxsim_exact = weighted_maxsim*exact_match\n",
    "                weighted_maxsim_semantic = weighted_maxsim*semantic_match\n",
    "                # get the sum\n",
    "                numerator_exact = weighted_maxsim_exact.sum(1)\n",
    "                numerator_semantic = weighted_maxsim_semantic.sum(1)\n",
    "            df[\"exact_numer_exact\"] = numerator_exact.tolist()\n",
    "            df[\"semantic_numer_exact\"] = numerator_semantic.tolist()\n",
    "            df[\"exact_denom\"] = denominator.tolist()\n",
    "            df[\"exact_pct\"] = (numerator_exact/denominator).tolist()\n",
    "            df[\"semantic_pct\"] = (numerator_semantic/denominator).tolist()\n",
    "        df = df.drop(columns=['query_toks', 'query_embs'])\n",
    "        return df\n",
    "\n",
    "    return pt.apply.by_query(_score_query, add_ranks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "nasty-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_smp(df,cutoff):\n",
    "    smp = df[df['rank']<=cutoff].groupby(['qid','query']).mean().reset_index().sort_values(\"semantic_pct\", ascending=False).semantic_pct.mean()\n",
    "    return smp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-access",
   "metadata": {},
   "source": [
    "# RQ3.1: How does the semantic matching behaviour varying accross Col$\\star$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "electronic-seventh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3865912409894394"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_all=True))\n",
    "\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "infectious-tulsa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4063934326447822"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_all=True))\n",
    "\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-channels",
   "metadata": {},
   "source": [
    "# RQ3.2: Can we characterise the salient token families of matches, i.e., which type of tokens contribute the most to semantic matching?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-expression",
   "metadata": {},
   "source": [
    "## 3.2.1 Remarkble SMP: Question Token Family "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dental-laugh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:55:50.375 [main] WARN org.terrier.structures.BaseCompressingMetaIndex - Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 1.9 GiB of memory would be required.\n"
     ]
    }
   ],
   "source": [
    "bm25_terrier_stemmed_text = pt.BatchRetrieve.from_dataset(\n",
    "    'msmarco_passage', \n",
    "    'terrier_stemmed_text', \n",
    "    wmodel='BM25',\n",
    "    metadata=['docno', 'text'], \n",
    "    num_results=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "productive-recipient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08465427102251386"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_question=True))\n",
    "\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "killing-consultancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08659131377182826"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_question=True))\n",
    "\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-ethernet",
   "metadata": {},
   "source": [
    "## 3.2.2 Remarkble SMP: SubWord Token Family "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "peripheral-increase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008859794350146544"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_subword=True))\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cross-fourth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013382806993004948"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_subword=True))\n",
    "\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-writer",
   "metadata": {},
   "source": [
    "## 3.2.3 Remarkble SMP: Stopword Token Family "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "healthy-newspaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16249954805518138"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_stop=True))\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "surgical-lawsuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16867870545196612"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_stop=True))\n",
    "\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-divide",
   "metadata": {},
   "source": [
    "## 3.2.4 Remarkble SMP: Numeric Token Family "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "generic-welcome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017458915120925164"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_numeric=True))\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "drawn-affiliation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018937234838903954"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_numeric=True))\n",
    "\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-figure",
   "metadata": {},
   "source": [
    "## 3.2.5 Remarkble SMP: Stemming Token Family "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "secure-sauce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02244023500819399"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_stem=True))\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "descending-darwin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022583855134168457"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_stem=True))\n",
    "\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-precipitation",
   "metadata": {},
   "source": [
    "## 3.2.6 Remarkble SMP: Low$_{idf}$ Token Family "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "considerable-sodium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3648163944432631"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_low=True))\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aware-associate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38073608345706456"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_low=True))\n",
    "\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-sunglasses",
   "metadata": {},
   "source": [
    "## 3.2.7 Remarkble SMP: Med$_{idf}$ Token Family "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "smoking-scope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021035169828244132"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_med=True))\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "brown-peter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024605643697183342"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_med=True))\n",
    "\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-mambo",
   "metadata": {},
   "source": [
    "## 3.2.8 Remarkble SMP: High$_{idf}$ Token Family "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "chemical-compromise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007396773858503861"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "pipe= (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_high=True))\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "directed-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010517060957372388"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = (factory.end_to_end()%100\n",
    "        >>factory.fetch_index_encodings(ids=True)\n",
    "        >>scorer_smp(factory,add_high=True))\n",
    "\n",
    "res =pd.concat(pipe.transform_gen(topics2020,batch_size=1))\n",
    "smp_cutoff10 = report_smp(res, cutoff=10)\n",
    "smp_cutoff10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-leadership",
   "metadata": {},
   "source": [
    "# Conclusion for RQ 3.2\n",
    "\n",
    "Overall, in response to RQ3.2, in quantifying the extent of semantic matching for various token families, we find that low IDF tokens are most likely to exhibit semantic matching. \n",
    "\n",
    "Similarly, the above experiments can be applied for ColminiLM directly, and ColRoBERTa as well as ColALBERT with minimal changes in terms of the special token ids for each variant model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-stadium",
   "metadata": {},
   "source": [
    "# RQ3.3 Can we quantify the contribution of different types of matching behaviour, namely the lexical match and semantic match as well as specialtoken match, to the retrieval effectiveness? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "quality-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_match_matrix_RQ4(maxsim, idx,idsQ,idsD):\n",
    "    exact_match = torch.zeros_like(maxsim)\n",
    "    semantic_match = torch.zeros_like(maxsim)\n",
    "    for didx in range(len(idx)): \n",
    "        for qidx in range(len(idsQ[0])): \n",
    "            q_tid=idsQ[0][qidx]\n",
    "            max_dtok_index = idx[didx][qidx]\n",
    "            doc_maxsim_tid = idsD[didx][max_dtok_index]\n",
    "            if (q_tid == doc_maxsim_tid):\n",
    "                exact_match[didx][qidx]=1\n",
    "            if (q_tid != doc_maxsim_tid):\n",
    "                semantic_match[didx][qidx]=1\n",
    "    return exact_match, semantic_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "pediatric-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier.transformer import TransformerBase\n",
    "def scorer_quantify_contribution(factory, add_contributions=False, add_exact_match_contribution=False, all_types_scoring=False,\n",
    "                 only_exact_scoring=False, only_semantic_scoring=False, only_special_scoring=False,only_qtokens_scoring=False,\n",
    "                 verbose=False, gpu=True) -> TransformerBase:\n",
    "    \"\"\"\n",
    "    Calculates the ColBERT max_sim operator using previous encodings of queries and documents\n",
    "    input: qid, query_embs, [query_weights], docno, doc_embs\n",
    "    output: ditto + score, [+ contributions]\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import pyterrier as pt\n",
    "    assert pt.started(), 'PyTerrier must be started'\n",
    "    cuda0 = torch.device('cuda') if gpu else torch.device('cpu')\n",
    "\n",
    "    def _build_interaction(row, D):\n",
    "        doc_embs = row.doc_embs\n",
    "        doc_len = doc_embs.shape[0]\n",
    "        D[row.row_index, 0:doc_len, :] = doc_embs\n",
    "\n",
    "    def _build_toks(row, idsD):\n",
    "        doc_toks = row.doc_toks\n",
    "        doc_len = doc_toks.shape[0]\n",
    "        idsD[row.row_index, 0:doc_len] = doc_toks\n",
    "\n",
    "    def _score_query(df):\n",
    "        with torch.no_grad():\n",
    "            weightsQ = None\n",
    "            Q = torch.cat([df.iloc[0].query_embs])\n",
    "            if \"query_weights\" in df.columns:\n",
    "                weightsQ = df.iloc[0].query_weights\n",
    "            else:\n",
    "                weightsQ = torch.ones(Q.shape[0])\n",
    "            if gpu:\n",
    "                Q = Q.cuda()\n",
    "                weightsQ = weightsQ.cuda()        \n",
    "            D = torch.zeros(len(df), factory.args.doc_maxlen, factory.args.dim, device=cuda0)\n",
    "            df['row_index'] = range(len(df))\n",
    "            if verbose:\n",
    "                pt.tqdm.pandas(desc='scorer')\n",
    "                df.progress_apply(lambda row: _build_interaction(row, D), axis=1)\n",
    "            else:\n",
    "                df.apply(lambda row: _build_interaction(row, D), axis=1)\n",
    "                \n",
    "            idsQ = torch.cat([df.iloc[0].query_toks]).unsqueeze(0)\n",
    "            idsD = torch.zeros(len(df), factory.args.doc_maxlen, dtype=idsQ.dtype)\n",
    "\n",
    "            df.apply(lambda row: _build_toks(row, idsD), axis=1)\n",
    "            token_match = (idsQ != 101) & (idsQ != 102) & (idsQ != 103) & (idsQ != 1) & (idsQ != 2)\n",
    "\n",
    "            interaction = (Q @ D.permute(0, 2, 1)).cpu()\n",
    "            maxsim, idx = interaction.max(2)\n",
    "            \n",
    "            exact_match, semantic_match =_get_match_matrix_RQ4(maxsim, idx, idsQ, idsD)\n",
    "            exact_match[:, ~token_match[0,:]] = 0\n",
    "            semantic_match[:, ~token_match[0,:]] = 0\n",
    "\n",
    "            weightsQ = weightsQ.unsqueeze(0).cpu()\n",
    "            weighted_maxsim = weightsQ*maxsim\n",
    "\n",
    "            weighted_maxsim_exact = weighted_maxsim*exact_match\n",
    "            weighted_maxsim_semantic = weighted_maxsim*semantic_match\n",
    "\n",
    "            if only_exact_scoring:\n",
    "                df[\"score\"] = weighted_maxsim_exact.sum(1).cpu().tolist()\n",
    "    \n",
    "            elif only_semantic_scoring:\n",
    "                df[\"score\"] = weighted_maxsim_semantic.sum(1).cpu().tolist()\n",
    "            elif only_special_scoring:\n",
    "                special_token_match = (idsQ == 101) | (idsQ == 102) | (idsQ == 1) | (idsQ == 2) |(idsQ == 103)\n",
    "\n",
    "                interaction = (Q @ D.permute(0, 2, 1)).cpu()\n",
    "\n",
    "                weighted_maxsim = weightsQ*interaction.max(2).values\n",
    "          \n",
    "                weighted_maxsim[:, ~special_token_match[0,:]] = 0\n",
    "                df[\"score\"] = weighted_maxsim.sum(1).cpu().tolist()\n",
    "                \n",
    "            elif all_types_scoring:\n",
    "                maxscoreQ = (Q @ D.permute(0, 2, 1)).max(2).values\n",
    "                maxscoreQ = maxscoreQ.cpu()\n",
    "                scores = (weightsQ*maxscoreQ).sum(1)\n",
    "                df[\"score\"] = scores.tolist()\n",
    "        return df\n",
    "\n",
    "    return pt.apply.by_query(_score_query, add_ranks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "basic-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_pipe_only_exact = (\n",
    "    factory.set_retrieve()\n",
    "    >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)\n",
    "    >> factory.fetch_index_encodings(ids=True)\n",
    "    >> scorer_quantify_contribution(factory,only_exact_scoring=True,only_semantic_scoring=False,only_special_scoring=False,all_types_scoring=False)\n",
    ")\n",
    "\n",
    "e2e_pipe_only_semantic = (\n",
    "    factory.set_retrieve()\n",
    "    >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)\n",
    "    >> factory.fetch_index_encodings(ids=True)\n",
    "    >> scorer_quantify_contribution(factory,only_exact_scoring=False,only_semantic_scoring=True,only_special_scoring=False,all_types_scoring=False)\n",
    ")\n",
    "\n",
    "\n",
    "e2e_pipe_only_qspecial = (\n",
    "    factory.set_retrieve() \n",
    "    >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)\n",
    "    >> factory.fetch_index_encodings(ids=True)\n",
    "    >> scorer_quantify_contribution(factory,only_exact_scoring=False,only_semantic_scoring=False,only_special_scoring=True,all_types_scoring=False)\n",
    ")\n",
    "\n",
    "\n",
    "e2e_pipe_all_types = (\n",
    "    factory.set_retrieve()\n",
    "    >> factory.index_scorer(query_encoded=True, add_ranks=True, batch_size=10000)\n",
    "    >> factory.fetch_index_encodings(ids=True)\n",
    "    >> scorer_quantify_contribution(factory,only_exact_scoring=False,only_semantic_scoring=False,only_special_scoring=False,all_types_scoring=True)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "backed-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pt.get_dataset(\"irds:msmarco-passage\")\n",
    "reranker_all_types = (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "       >> scorer_quantify_contribution(factory,only_exact_scoring=False,only_semantic_scoring=False,only_special_scoring=False,all_types_scoring=True)\n",
    ")\n",
    "\n",
    "reranker_only_exact = (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "       >> scorer_quantify_contribution(factory,only_exact_scoring=True,only_semantic_scoring=False,only_special_scoring=False,all_types_scoring=False)\n",
    ")\n",
    "\n",
    "reranker_only_semantic = (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "       >> scorer_quantify_contribution(factory,only_exact_scoring=False,only_semantic_scoring=True,only_special_scoring=False,all_types_scoring=False)\n",
    ")\n",
    "\n",
    "reranker_only_qspecial = (factory.query_encoder() >>bm25_terrier_stemmed_text>>pt.text.get_text(dataset,\"text\")>>factory.text_encoder() \n",
    "       >>factory.fetch_index_encodings(ids=True)\n",
    "       >> scorer_quantify_contribution(factory,only_exact_scoring=False,only_semantic_scoring=False,only_special_scoring=True,all_types_scoring=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cathedral-russell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_40c38_row0_col4,#T_40c38_row1_col4,#T_40c38_row2_col4,#T_40c38_row3_col4,#T_40c38_row4_col1,#T_40c38_row4_col2,#T_40c38_row4_col3,#T_40c38_row4_col4,#T_40c38_row4_col5,#T_40c38_row4_col6,#T_40c38_row4_col7{\n",
       "            font-weight:  bold;\n",
       "        }</style><table id=\"T_40c38_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >name</th>        <th class=\"col_heading level0 col1\" >nDCG@10</th>        <th class=\"col_heading level0 col2\" >nDCG@100</th>        <th class=\"col_heading level0 col3\" >R(rel=2)@100</th>        <th class=\"col_heading level0 col4\" >R(rel=2)@1000</th>        <th class=\"col_heading level0 col5\" >AP(rel=2)@100</th>        <th class=\"col_heading level0 col6\" >AP(rel=2)@1000</th>        <th class=\"col_heading level0 col7\" >RR(rel=2)@10</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_40c38_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_40c38_row0_col0\" class=\"data row0 col0\" >bm25</td>\n",
       "                        <td id=\"T_40c38_row0_col1\" class=\"data row0 col1\" >0.493627</td>\n",
       "                        <td id=\"T_40c38_row0_col2\" class=\"data row0 col2\" >0.502562</td>\n",
       "                        <td id=\"T_40c38_row0_col3\" class=\"data row0 col3\" >0.583855</td>\n",
       "                        <td id=\"T_40c38_row0_col4\" class=\"data row0 col4\" >0.807223</td>\n",
       "                        <td id=\"T_40c38_row0_col5\" class=\"data row0 col5\" >0.275282</td>\n",
       "                        <td id=\"T_40c38_row0_col6\" class=\"data row0 col6\" >0.292988</td>\n",
       "                        <td id=\"T_40c38_row0_col7\" class=\"data row0 col7\" >0.614675</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_40c38_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_40c38_row1_col0\" class=\"data row1 col0\" >reranker.only_exact</td>\n",
       "                        <td id=\"T_40c38_row1_col1\" class=\"data row1 col1\" >0.526527</td>\n",
       "                        <td id=\"T_40c38_row1_col2\" class=\"data row1 col2\" >0.529497</td>\n",
       "                        <td id=\"T_40c38_row1_col3\" class=\"data row1 col3\" >0.610375</td>\n",
       "                        <td id=\"T_40c38_row1_col4\" class=\"data row1 col4\" >0.807223</td>\n",
       "                        <td id=\"T_40c38_row1_col5\" class=\"data row1 col5\" >0.315803</td>\n",
       "                        <td id=\"T_40c38_row1_col6\" class=\"data row1 col6\" >0.334937</td>\n",
       "                        <td id=\"T_40c38_row1_col7\" class=\"data row1 col7\" >0.655093</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_40c38_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_40c38_row2_col0\" class=\"data row2 col0\" >reranker.only_semantic</td>\n",
       "                        <td id=\"T_40c38_row2_col1\" class=\"data row2 col1\" >0.138996</td>\n",
       "                        <td id=\"T_40c38_row2_col2\" class=\"data row2 col2\" >0.176649</td>\n",
       "                        <td id=\"T_40c38_row2_col3\" class=\"data row2 col3\" >0.270707</td>\n",
       "                        <td id=\"T_40c38_row2_col4\" class=\"data row2 col4\" >0.807223</td>\n",
       "                        <td id=\"T_40c38_row2_col5\" class=\"data row2 col5\" >0.078337</td>\n",
       "                        <td id=\"T_40c38_row2_col6\" class=\"data row2 col6\" >0.097151</td>\n",
       "                        <td id=\"T_40c38_row2_col7\" class=\"data row2 col7\" >0.234744</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_40c38_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_40c38_row3_col0\" class=\"data row3 col0\" >reranker.only_special</td>\n",
       "                        <td id=\"T_40c38_row3_col1\" class=\"data row3 col1\" >0.518976</td>\n",
       "                        <td id=\"T_40c38_row3_col2\" class=\"data row3 col2\" >0.476350</td>\n",
       "                        <td id=\"T_40c38_row3_col3\" class=\"data row3 col3\" >0.581121</td>\n",
       "                        <td id=\"T_40c38_row3_col4\" class=\"data row3 col4\" >0.807223</td>\n",
       "                        <td id=\"T_40c38_row3_col5\" class=\"data row3 col5\" >0.318272</td>\n",
       "                        <td id=\"T_40c38_row3_col6\" class=\"data row3 col6\" >0.334874</td>\n",
       "                        <td id=\"T_40c38_row3_col7\" class=\"data row3 col7\" >0.713889</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_40c38_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_40c38_row4_col0\" class=\"data row4 col0\" >reranker.all_types</td>\n",
       "                        <td id=\"T_40c38_row4_col1\" class=\"data row4 col1\" >0.706804</td>\n",
       "                        <td id=\"T_40c38_row4_col2\" class=\"data row4 col2\" >0.645974</td>\n",
       "                        <td id=\"T_40c38_row4_col3\" class=\"data row4 col3\" >0.711896</td>\n",
       "                        <td id=\"T_40c38_row4_col4\" class=\"data row4 col4\" >0.807223</td>\n",
       "                        <td id=\"T_40c38_row4_col5\" class=\"data row4 col5\" >0.471695</td>\n",
       "                        <td id=\"T_40c38_row4_col6\" class=\"data row4 col6\" >0.483810</td>\n",
       "                        <td id=\"T_40c38_row4_col7\" class=\"data row4 col7\" >0.834877</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_40c38_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_40c38_row5_col0\" class=\"data row5 col0\" >colbert.only_exact</td>\n",
       "                        <td id=\"T_40c38_row5_col1\" class=\"data row5 col1\" >0.492102</td>\n",
       "                        <td id=\"T_40c38_row5_col2\" class=\"data row5 col2\" >0.485153</td>\n",
       "                        <td id=\"T_40c38_row5_col3\" class=\"data row5 col3\" >0.572707</td>\n",
       "                        <td id=\"T_40c38_row5_col4\" class=\"data row5 col4\" >0.771416</td>\n",
       "                        <td id=\"T_40c38_row5_col5\" class=\"data row5 col5\" >0.284611</td>\n",
       "                        <td id=\"T_40c38_row5_col6\" class=\"data row5 col6\" >0.301504</td>\n",
       "                        <td id=\"T_40c38_row5_col7\" class=\"data row5 col7\" >0.646781</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_40c38_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_40c38_row6_col0\" class=\"data row6 col0\" >colbert.only_semantic</td>\n",
       "                        <td id=\"T_40c38_row6_col1\" class=\"data row6 col1\" >0.002188</td>\n",
       "                        <td id=\"T_40c38_row6_col2\" class=\"data row6 col2\" >0.009526</td>\n",
       "                        <td id=\"T_40c38_row6_col3\" class=\"data row6 col3\" >0.023642</td>\n",
       "                        <td id=\"T_40c38_row6_col4\" class=\"data row6 col4\" >0.113610</td>\n",
       "                        <td id=\"T_40c38_row6_col5\" class=\"data row6 col5\" >0.001450</td>\n",
       "                        <td id=\"T_40c38_row6_col6\" class=\"data row6 col6\" >0.002780</td>\n",
       "                        <td id=\"T_40c38_row6_col7\" class=\"data row6 col7\" >0.004630</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_40c38_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_40c38_row7_col0\" class=\"data row7 col0\" >colbert.only_speical</td>\n",
       "                        <td id=\"T_40c38_row7_col1\" class=\"data row7 col1\" >0.383874</td>\n",
       "                        <td id=\"T_40c38_row7_col2\" class=\"data row7 col2\" >0.316111</td>\n",
       "                        <td id=\"T_40c38_row7_col3\" class=\"data row7 col3\" >0.376110</td>\n",
       "                        <td id=\"T_40c38_row7_col4\" class=\"data row7 col4\" >0.554282</td>\n",
       "                        <td id=\"T_40c38_row7_col5\" class=\"data row7 col5\" >0.216956</td>\n",
       "                        <td id=\"T_40c38_row7_col6\" class=\"data row7 col6\" >0.224973</td>\n",
       "                        <td id=\"T_40c38_row7_col7\" class=\"data row7 col7\" >0.568078</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_40c38_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_40c38_row8_col0\" class=\"data row8 col0\" >colbert.all_types</td>\n",
       "                        <td id=\"T_40c38_row8_col1\" class=\"data row8 col1\" >0.689939</td>\n",
       "                        <td id=\"T_40c38_row8_col2\" class=\"data row8 col2\" >0.623477</td>\n",
       "                        <td id=\"T_40c38_row8_col3\" class=\"data row8 col3\" >0.704708</td>\n",
       "                        <td id=\"T_40c38_row8_col4\" class=\"data row8 col4\" >0.805692</td>\n",
       "                        <td id=\"T_40c38_row8_col5\" class=\"data row8 col5\" >0.461100</td>\n",
       "                        <td id=\"T_40c38_row8_col6\" class=\"data row8 col6\" >0.472455</td>\n",
       "                        <td id=\"T_40c38_row8_col7\" class=\"data row8 col7\" >0.831790</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f33f43dcfd0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "res1 = pt.Experiment(\n",
    "    [\n",
    "    bm25_terrier_stemmed_text,\n",
    "    reranker_only_exact,\n",
    "    reranker_only_semantic,\n",
    "    reranker_only_qspecial,\n",
    "    reranker_all_types,\n",
    "    e2e_pipe_only_exact,\n",
    "    e2e_pipe_only_semantic,\n",
    "    e2e_pipe_only_qspecial,\n",
    "    e2e_pipe_all_types\n",
    "    ],\n",
    "    topics2020,\n",
    "    qrels2020,\n",
    "    save_dir=\"./\",\n",
    "    filter_by_qrels=True,\n",
    "    batch_size=10,verbose=True,\n",
    "    eval_metrics = [nDCG@10,nDCG@100, R(rel=2)@100,R(rel=2)@1000, AP(rel=2)@100,AP(rel=2)@1000,RR(rel=2)@10], # Note: using R@1000 here instead of R(rel=2)@1000 to match the measure used by the TCT-ColBERT paper\n",
    "    names=[\n",
    "        'bm25',\n",
    "        \"reranker.only_exact\",\"reranker.only_semantic\",\n",
    "        \"reranker.only_special\",\"reranker.all_types\",\n",
    "        \"colbert.only_exact\",\"colbert.only_semantic\",\n",
    "        \"colbert.only_speical\",\"colbert.all_types\"]\n",
    ")\n",
    "\n",
    "res1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-freeze",
   "metadata": {},
   "source": [
    "### Note: for other Col$\\star$ models, you need make a small change about the \"special_token_match\". Or, instead, you can directly evaluate our provided result files to reproduce the results reported in the Table7 of our paper.  In the following, the experiment demonstrate this evaluation for all the reported models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-analysis",
   "metadata": {},
   "source": [
    "#### Table7 results for ColBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "statutory-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_only_exact = pt.io.read_results(\"./ColBERT/colbert.only_exact.res.gz\")\n",
    "e2e_only_semantic = pt.io.read_results(\"./ColBERT/colbert.only_semantic.res.gz\")\n",
    "e2e_only_special = pt.io.read_results(\"./ColBERT/colbert.only_special.res.gz\")\n",
    "e2e_all_types = pt.io.read_results(\"./ColBERT/colbert.all_types.res.gz\")\n",
    "\n",
    "rerank_only_exact = pt.io.read_results(\"./ColBERT/reranker.only_exact.res.gz\")\n",
    "rerank_only_semantic = pt.io.read_results(\"./ColBERT/reranker.only_semantic.res.gz\")\n",
    "rerank_only_special = pt.io.read_results(\"./ColBERT/reranker.only_special.res.gz\")\n",
    "rerank_all_types = pt.io.read_results(\"./ColBERT/reranker.all_types.res.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incorporated-clark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d054ac096f6f43eea8946cbf5a2208ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='pt.Experiment'), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reranker.only_exact</td>\n",
       "      <td>0.526527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reranker.only_semantic</td>\n",
       "      <td>0.138996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reranker.only_special</td>\n",
       "      <td>0.518976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reranker.all_types</td>\n",
       "      <td>0.706804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colbert.only_exact</td>\n",
       "      <td>0.492102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>colbert.only_semantic</td>\n",
       "      <td>0.002188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>colbert.only_speical</td>\n",
       "      <td>0.383874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>colbert.all_types</td>\n",
       "      <td>0.689939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name   nDCG@10\n",
       "0     reranker.only_exact  0.526527\n",
       "1  reranker.only_semantic  0.138996\n",
       "2   reranker.only_special  0.518976\n",
       "3      reranker.all_types  0.706804\n",
       "4      colbert.only_exact  0.492102\n",
       "5   colbert.only_semantic  0.002188\n",
       "6    colbert.only_speical  0.383874\n",
       "7       colbert.all_types  0.689939"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "res_colbert_RQ3_3 = pt.Experiment(\n",
    "    [\n",
    "    rerank_only_exact,\n",
    "    rerank_only_semantic,\n",
    "    rerank_only_special,\n",
    "    rerank_all_types,\n",
    "    e2e_only_exact,\n",
    "    e2e_only_semantic,\n",
    "    e2e_only_special,\n",
    "    e2e_all_types\n",
    "    ],\n",
    "    pt.get_dataset(\"trec-deep-learning-passages\").get_topics('test-2020'),\n",
    "    pt.get_dataset(\"trec-deep-learning-passages\").get_qrels('test-2020'),\n",
    "\n",
    "    filter_by_qrels=True,\n",
    "    batch_size=100,verbose=True,\n",
    "    eval_metrics = [nDCG@10], # Note: using R@1000 here instead of R(rel=2)@1000 to match the measure used by the TCT-ColBERT paper\n",
    "    names=[\n",
    "      \n",
    "        \"reranker.only_exact\",\"reranker.only_semantic\",\n",
    "        \"reranker.only_special\",\"reranker.all_types\",\n",
    "        \"colbert.only_exact\",\"colbert.only_semantic\",\n",
    "        \"colbert.only_speical\",\"colbert.all_types\"]\n",
    ")\n",
    "\n",
    "res_colbert_RQ3_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-cylinder",
   "metadata": {},
   "source": [
    "#### Table7 results for ColminiLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "moderate-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_only_exact = pt.io.read_results(\"./ColminiLM/colminilm.only_exact.res.gz\")\n",
    "e2e_only_semantic = pt.io.read_results(\"./ColminiLM/colminilm.only_semantic.res.gz\")\n",
    "e2e_only_special = pt.io.read_results(\"./ColminiLM/colminilm.only_special.res.gz\")\n",
    "e2e_all_types = pt.io.read_results(\"./ColminiLM/colminilm.all_types.res.gz\")\n",
    "\n",
    "rerank_only_exact = pt.io.read_results(\"./ColminiLM/colminilm.reranker.only_exact.res.gz\")\n",
    "rerank_only_semantic = pt.io.read_results(\"./ColminiLM/colminilm.reranker.only_semantic.res.gz\")\n",
    "rerank_only_special = pt.io.read_results(\"./ColminiLM/colminilm.reranker.only_special.res.gz\")\n",
    "rerank_all_types = pt.io.read_results(\"./ColminiLM/colminilm.reranker.all_types.res.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "selected-vietnam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086c62ed522b473ab48d007ca987d3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='pt.Experiment'), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colminilm.reranker.only_exact</td>\n",
       "      <td>0.487370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>colminilm.reranker.only_semantic</td>\n",
       "      <td>0.074291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>colminilm.reranker.only_special</td>\n",
       "      <td>0.522579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colminilm.reranker.all_types</td>\n",
       "      <td>0.684679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colminilm.only_exact</td>\n",
       "      <td>0.426379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>colminilm.only_semantic</td>\n",
       "      <td>0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>colminilm.only_speical</td>\n",
       "      <td>0.346634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>colminilm.all_types</td>\n",
       "      <td>0.672129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name   nDCG@10\n",
       "0     colminilm.reranker.only_exact  0.487370\n",
       "1  colminilm.reranker.only_semantic  0.074291\n",
       "2   colminilm.reranker.only_special  0.522579\n",
       "3      colminilm.reranker.all_types  0.684679\n",
       "4              colminilm.only_exact  0.426379\n",
       "5           colminilm.only_semantic  0.000563\n",
       "6            colminilm.only_speical  0.346634\n",
       "7               colminilm.all_types  0.672129"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "res_colminilm_RQ3_3 = pt.Experiment(\n",
    "    [\n",
    "    rerank_only_exact,\n",
    "    rerank_only_semantic,\n",
    "    rerank_only_special,\n",
    "    rerank_all_types,\n",
    "    e2e_only_exact,\n",
    "    e2e_only_semantic,\n",
    "    e2e_only_special,\n",
    "    e2e_all_types\n",
    "    ],\n",
    "    pt.get_dataset(\"trec-deep-learning-passages\").get_topics('test-2020'),\n",
    "    pt.get_dataset(\"trec-deep-learning-passages\").get_qrels('test-2020'),\n",
    "\n",
    "    filter_by_qrels=True,\n",
    "    batch_size=100,verbose=True,\n",
    "    eval_metrics = [nDCG@10], # Note: using R@1000 here instead of R(rel=2)@1000 to match the measure used by the TCT-ColBERT paper\n",
    "    names=[\n",
    "      \n",
    "        \"colminilm.reranker.only_exact\",\"colminilm.reranker.only_semantic\",\n",
    "        \"colminilm.reranker.only_special\",\"colminilm.reranker.all_types\",\n",
    "        \"colminilm.only_exact\",\"colminilm.only_semantic\",\n",
    "        \"colminilm.only_speical\",\"colminilm.all_types\"]\n",
    ")\n",
    "\n",
    "res_colminilm_RQ3_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-nerve",
   "metadata": {},
   "source": [
    "#### Table7 results for ColRoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "consecutive-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_only_exact = pt.io.read_results(\"./ColRoBERTa/colroberta.only_exact.res.gz\")\n",
    "e2e_only_semantic = pt.io.read_results(\"./ColRoBERTa/colroberta.only_semantic.res.gz\")\n",
    "e2e_only_special = pt.io.read_results(\"./ColRoBERTa/colroberta.only_special.res.gz\")\n",
    "e2e_all_types = pt.io.read_results(\"./ColRoBERTa/colroberta.all_types.res.gz\")\n",
    "\n",
    "rerank_only_exact = pt.io.read_results(\"./ColRoBERTa/colroberta.reranker.only_exact.res.gz\")\n",
    "rerank_only_semantic = pt.io.read_results(\"./ColRoBERTa/colroberta.reranker.only_semantic.res.gz\")\n",
    "rerank_only_special = pt.io.read_results(\"./ColRoBERTa/colroberta.reranker.only_special.res.gz\")\n",
    "rerank_all_types = pt.io.read_results(\"./ColRoBERTa/colroberta.reranker.all_types.res.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "crucial-texture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a9a0beb41f40ffa9660e0844db781e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='pt.Experiment'), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colroberta.reranker.only_exact</td>\n",
       "      <td>0.396841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>colroberta.reranker.only_semantic</td>\n",
       "      <td>0.260481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>colroberta.reranker.only_special</td>\n",
       "      <td>0.635353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colroberta.reranker.all_types</td>\n",
       "      <td>0.695075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colroberta.only_exact</td>\n",
       "      <td>0.349475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>colroberta.only_semantic</td>\n",
       "      <td>0.157172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>colroberta.only_speical</td>\n",
       "      <td>0.574166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>colroberta.all_types</td>\n",
       "      <td>0.666198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name   nDCG@10\n",
       "0     colroberta.reranker.only_exact  0.396841\n",
       "1  colroberta.reranker.only_semantic  0.260481\n",
       "2   colroberta.reranker.only_special  0.635353\n",
       "3      colroberta.reranker.all_types  0.695075\n",
       "4              colroberta.only_exact  0.349475\n",
       "5           colroberta.only_semantic  0.157172\n",
       "6            colroberta.only_speical  0.574166\n",
       "7               colroberta.all_types  0.666198"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "res_colroberta_RQ3_3 = pt.Experiment(\n",
    "    [\n",
    "    rerank_only_exact,\n",
    "    rerank_only_semantic,\n",
    "    rerank_only_special,\n",
    "    rerank_all_types,\n",
    "    e2e_only_exact,\n",
    "    e2e_only_semantic,\n",
    "    e2e_only_special,\n",
    "    e2e_all_types\n",
    "    ],\n",
    "    pt.get_dataset(\"trec-deep-learning-passages\").get_topics('test-2020'),\n",
    "    pt.get_dataset(\"trec-deep-learning-passages\").get_qrels('test-2020'),\n",
    "\n",
    "    filter_by_qrels=True,\n",
    "    batch_size=100,verbose=True,\n",
    "    eval_metrics = [nDCG@10], # Note: using R@1000 here instead of R(rel=2)@1000 to match the measure used by the TCT-ColBERT paper\n",
    "    names=[\n",
    "      \n",
    "        \"colroberta.reranker.only_exact\",\"colroberta.reranker.only_semantic\",\n",
    "        \"colroberta.reranker.only_special\",\"colroberta.reranker.all_types\",\n",
    "        \"colroberta.only_exact\",\"colroberta.only_semantic\",\n",
    "        \"colroberta.only_speical\",\"colroberta.all_types\"]\n",
    ")\n",
    "\n",
    "res_colroberta_RQ3_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-machinery",
   "metadata": {},
   "source": [
    "#### Table7 results for ColALBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "challenging-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_only_exact = pt.io.read_results(\"./ColALBERT/colalbert.only_exact.res.gz\")\n",
    "e2e_only_semantic = pt.io.read_results(\"./ColALBERT/colalbert.only_semantic.res.gz\")\n",
    "e2e_only_special = pt.io.read_results(\"./ColALBERT/colalbert.only_special.res.gz\")\n",
    "e2e_all_types = pt.io.read_results(\"./ColALBERT/colalbert.all_types.res.gz\")\n",
    "\n",
    "rerank_only_exact = pt.io.read_results(\"./ColALBERT/colalbert.reranker.only_exact.res.gz\")\n",
    "rerank_only_semantic = pt.io.read_results(\"./ColALBERT/colalbert.reranker.only_semantic.res.gz\")\n",
    "rerank_only_special = pt.io.read_results(\"./ColALBERT/colalbert.reranker.only_special.res.gz\")\n",
    "rerank_all_types = pt.io.read_results(\"./ColALBERT/colalbert.reranker.all_types.res.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "medical-canal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cc45e3285546d0a2eba8591535331d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='pt.Experiment'), FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>colalbert.reranker.only_exact</td>\n",
       "      <td>0.505309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>colalbert.reranker.only_semantic</td>\n",
       "      <td>0.074438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>colalbert.reranker.only_special</td>\n",
       "      <td>0.459578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>colalbert.reranker.all_types</td>\n",
       "      <td>0.630362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colalbert.only_exact</td>\n",
       "      <td>0.410674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>colalbert.only_semantic</td>\n",
       "      <td>0.007132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>colalbert.only_speical</td>\n",
       "      <td>0.341385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>colalbert.all_types</td>\n",
       "      <td>0.603873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name   nDCG@10\n",
       "0     colalbert.reranker.only_exact  0.505309\n",
       "1  colalbert.reranker.only_semantic  0.074438\n",
       "2   colalbert.reranker.only_special  0.459578\n",
       "3      colalbert.reranker.all_types  0.630362\n",
       "4              colalbert.only_exact  0.410674\n",
       "5           colalbert.only_semantic  0.007132\n",
       "6            colalbert.only_speical  0.341385\n",
       "7               colalbert.all_types  0.603873"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import *\n",
    "res_colalbert_RQ3_3 = pt.Experiment(\n",
    "    [\n",
    "    rerank_only_exact,\n",
    "    rerank_only_semantic,\n",
    "    rerank_only_special,\n",
    "    rerank_all_types,\n",
    "    e2e_only_exact,\n",
    "    e2e_only_semantic,\n",
    "    e2e_only_special,\n",
    "    e2e_all_types\n",
    "    ],\n",
    "    pt.get_dataset(\"trec-deep-learning-passages\").get_topics('test-2020'),\n",
    "    pt.get_dataset(\"trec-deep-learning-passages\").get_qrels('test-2020'),\n",
    "\n",
    "    filter_by_qrels=True,\n",
    "    batch_size=100,verbose=True,\n",
    "    eval_metrics = [nDCG@10], # Note: using R@1000 here instead of R(rel=2)@1000 to match the measure used by the TCT-ColBERT paper\n",
    "    names=[\n",
    "      \n",
    "        \"colalbert.reranker.only_exact\",\"colalbert.reranker.only_semantic\",\n",
    "        \"colalbert.reranker.only_special\",\"colalbert.reranker.all_types\",\n",
    "        \"colalbert.only_exact\",\"colalbert.only_semantic\",\n",
    "        \"colalbert.only_speical\",\"colalbert.all_types\"]\n",
    ")\n",
    "\n",
    "res_colalbert_RQ3_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-garbage",
   "metadata": {},
   "source": [
    "# Conclusion for RQ3.3\n",
    "\n",
    "In summary, based on the results above, to answer to RQ3.3, we find that the late interaction mechanism benefits more from lexical matching than semantic matching. In addition, special tokens, such as the \\texttt{[CLS]} token, play a very important role in matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-charge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
